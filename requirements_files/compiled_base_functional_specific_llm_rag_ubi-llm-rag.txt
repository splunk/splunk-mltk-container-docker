#
# This file is autogenerated by pip-compile with Python 3.9
# by the following command:
#
#    pip-compile /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
#
--extra-index-url https://download.pytorch.org/whl/cpu

absl-py==2.1.0
    # via
    #   keras
    #   tensorboard
    #   tensorflow
    #   tensorflow-cpu
aiofiles==24.1.0
    # via -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
aiohttp==3.9.5
    # via
    #   huggingface-hub
    #   jupyter-server-proxy
    #   llama-index-core
    #   llama-index-legacy
aiosignal==1.3.1
    # via aiohttp
alembic==1.13.2
    # via mlflow
aniso8601==9.0.1
    # via graphene
annotated-types==0.7.0
    # via pydantic
anthropic==0.28.1
    # via llama-index-llms-anthropic
anyio==4.4.0
    # via
    #   anthropic
    #   httpx
    #   jupyter-server
    #   openai
    #   starlette
    #   watchfiles
argon2-cffi==23.1.0
    # via jupyter-server
argon2-cffi-bindings==21.2.0
    # via argon2-cffi
arrow==1.3.0
    # via isoduration
arviz==0.17.1
    # via pymc3
asgiref==3.8.1
    # via opentelemetry-instrumentation-asgi
asttokens==2.4.1
    # via stack-data
astunparse==1.6.3
    # via
    #   tensorflow
    #   tensorflow-cpu
async-lru==2.0.4
    # via jupyterlab
async-timeout==4.0.3
    # via aiohttp
attrs==23.2.0
    # via
    #   aiohttp
    #   jsonschema
    #   referencing
azure-core==1.30.2
    # via azure-identity
azure-identity==1.17.1
    # via llama-index-llms-azure-openai
babel==2.15.0
    # via jupyterlab-server
backoff==2.2.1
    # via opentelemetry-exporter-otlp-proto-grpc
beautifulsoup4==4.12.3
    # via
    #   llama-index-readers-file
    #   nbconvert
bleach==6.1.0
    # via nbconvert
blinker==1.8.2
    # via flask
bocd==0.1.2
    # via -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
bokeh==3.4.2
    # via dask-labextension
boto3==1.34.144
    # via llama-index-llms-bedrock
botocore==1.34.144
    # via
    #   boto3
    #   s3transfer
cachetools==5.4.0
    # via
    #   mlflow
    #   pymc3
certifi==2024.7.4
    # via
    #   httpcore
    #   httpx
    #   requests
cffi==1.16.0
    # via
    #   argon2-cffi-bindings
    #   cryptography
charset-normalizer==3.3.2
    # via requests
click==8.1.7
    # via
    #   dask
    #   distributed
    #   flask
    #   mlflow
    #   nltk
    #   typer
    #   uvicorn
cloudpickle==3.0.0
    # via
    #   dask
    #   dask-glm
    #   distributed
    #   mlflow
    #   shap
cmdstanpy==1.2.4
    # via prophet
colorama==0.4.6
    # via nbdime
colorcet==3.1.0
    # via datashader
combo==0.1.3
    # via suod
comm==0.2.2
    # via
    #   ipykernel
    #   ipywidgets
contourpy==1.2.1
    # via
    #   bokeh
    #   matplotlib
cryptography==42.0.8
    # via
    #   azure-identity
    #   msal
    #   pyjwt
    #   pyopenssl
cycler==0.12.1
    # via matplotlib
dask[array,dataframe]==2024.7.0
    # via
    #   dask-expr
    #   dask-glm
    #   dask-ml
    #   dask-xgboost
    #   datashader
    #   distributed
dask-expr==1.1.7
    # via dask
dask-glm==0.3.2
    # via dask-ml
dask-labextension==7.0.0
    # via -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
dask-ml==2024.4.4
    # via -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
dask-xgboost==0.2.0
    # via -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
dataclasses-json==0.6.7
    # via
    #   llama-index-core
    #   llama-index-legacy
datashader==0.16.3
    # via -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
debugpy==1.8.2
    # via ipykernel
decorator==5.1.1
    # via ipython
defusedxml==0.7.1
    # via nbconvert
deprecated==1.2.14
    # via
    #   llama-index-core
    #   llama-index-legacy
    #   opentelemetry-api
    #   opentelemetry-propagator-b3
deprecation==2.1.0
    # via splunk-sdk
dill==0.3.8
    # via pymc3
dirtyjson==1.0.8
    # via
    #   llama-index-core
    #   llama-index-legacy
distributed==2024.7.0
    # via
    #   dask-glm
    #   dask-labextension
    #   dask-ml
    #   dask-xgboost
distro==1.9.0
    # via
    #   anthropic
    #   openai
dnspython==2.6.1
    # via email-validator
docker==7.1.0
    # via mlflow
docx2txt==0.8
    # via -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
email-validator==2.2.0
    # via fastapi
entrypoints==0.4
    # via mlflow
environs==9.5.0
    # via pymilvus
exceptiongroup==1.2.2
    # via
    #   anyio
    #   ipython
executing==2.0.1
    # via stack-data
fastapi==0.111.1
    # via -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
fastapi-cli==0.0.4
    # via fastapi
fastjsonschema==2.20.0
    # via nbformat
fastprogress==1.0.3
    # via pymc3
filelock==3.15.4
    # via
    #   huggingface-hub
    #   theano-pymc
    #   torch
    #   transformers
flask==3.0.3
    # via mlflow
flatbuffers==24.3.25
    # via
    #   tensorflow
    #   tensorflow-cpu
fonttools==4.53.1
    # via matplotlib
fqdn==1.5.1
    # via jsonschema
frozenlist==1.4.1
    # via
    #   aiohttp
    #   aiosignal
fsspec==2024.6.1
    # via
    #   dask
    #   huggingface-hub
    #   llama-index-core
    #   llama-index-legacy
    #   torch
gast==0.6.0
    # via
    #   tensorflow
    #   tensorflow-cpu
gitdb==4.0.11
    # via gitpython
gitpython==3.1.43
    # via
    #   mlflow
    #   nbdime
google-pasta==0.2.0
    # via
    #   tensorflow
    #   tensorflow-cpu
googleapis-common-protos==1.63.2
    # via opentelemetry-exporter-otlp-proto-grpc
graphene==3.3
    # via mlflow
graphql-core==3.2.3
    # via
    #   graphene
    #   graphql-relay
graphql-relay==3.2.0
    # via graphene
greenlet==3.0.3
    # via sqlalchemy
grpcio==1.63.0
    # via
    #   opentelemetry-exporter-otlp-proto-grpc
    #   pymilvus
    #   tensorboard
    #   tensorflow
    #   tensorflow-cpu
gunicorn==22.0.0
    # via mlflow
h11==0.14.0
    # via
    #   httpcore
    #   uvicorn
h5netcdf==1.3.0
    # via arviz
h5py==3.11.0
    # via
    #   h5netcdf
    #   keras
    #   tensorflow
    #   tensorflow-cpu
holidays==0.53
    # via prophet
httpcore==1.0.5
    # via httpx
httptools==0.6.1
    # via uvicorn
httpx==0.27.0
    # via
    #   anthropic
    #   fastapi
    #   jupyterlab
    #   llama-cloud
    #   llama-index-core
    #   llama-index-legacy
    #   llama-index-llms-azure-openai
    #   openai
huggingface-hub[inference]==0.23.5
    # via
    #   llama-index-embeddings-huggingface
    #   sentence-transformers
    #   tokenizers
    #   transformers
idna==3.7
    # via
    #   anyio
    #   email-validator
    #   httpx
    #   jsonschema
    #   requests
    #   yarl
imageio==2.34.2
    # via scikit-image
imbalanced-learn==0.12.3
    # via -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
importlib-metadata==7.2.1
    # via
    #   dask
    #   flask
    #   jupyter-client
    #   jupyter-lsp
    #   jupyter-server-proxy
    #   jupyterlab
    #   jupyterlab-server
    #   markdown
    #   mlflow
    #   nbconvert
importlib-resources==6.4.0
    # via
    #   matplotlib
    #   prophet
instructorembedding==1.0.1
    # via llama-index-embeddings-instructor
ipykernel==6.29.5
    # via jupyterlab
ipython==8.18.1
    # via
    #   ipykernel
    #   ipywidgets
ipywidgets==8.1.3
    # via -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
isoduration==20.11.0
    # via jsonschema
itsdangerous==2.2.0
    # via flask
jedi==0.19.1
    # via ipython
jinja2==3.1.4
    # via
    #   bokeh
    #   distributed
    #   fastapi
    #   flask
    #   jupyter-server
    #   jupyterlab
    #   jupyterlab-server
    #   mlflow
    #   nbconvert
    #   nbdime
    #   torch
jiter==0.5.0
    # via anthropic
jmespath==1.0.1
    # via
    #   boto3
    #   botocore
joblib==1.4.2
    # via
    #   combo
    #   imbalanced-learn
    #   kmodes
    #   nltk
    #   pynndescent
    #   pyod
    #   scikit-learn
    #   suod
    #   tslearn
json5==0.9.25
    # via jupyterlab-server
jsonpointer==3.0.0
    # via jsonschema
jsonschema[format-nongpl]==4.23.0
    # via
    #   jupyter-events
    #   jupyterlab-server
    #   nbformat
jsonschema-specifications==2023.12.1
    # via jsonschema
jupyter-client==8.6.2
    # via
    #   ipykernel
    #   jupyter-server
    #   nbclient
jupyter-core==5.7.2
    # via
    #   ipykernel
    #   jupyter-client
    #   jupyter-server
    #   jupyterlab
    #   nbclient
    #   nbconvert
    #   nbformat
jupyter-events==0.10.0
    # via jupyter-server
jupyter-lsp==2.2.5
    # via jupyterlab
jupyter-server==2.14.2
    # via
    #   jupyter-lsp
    #   jupyter-server-mathjax
    #   jupyter-server-proxy
    #   jupyterlab
    #   jupyterlab-git
    #   jupyterlab-server
    #   nbdime
    #   notebook-shim
jupyter-server-mathjax==0.2.6
    # via nbdime
jupyter-server-proxy==4.3.0
    # via dask-labextension
jupyter-server-terminals==0.5.3
    # via jupyter-server
jupyterlab==4.2.3
    # via
    #   -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
    #   dask-labextension
jupyterlab-git==0.50.1
    # via -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
jupyterlab-pygments==0.3.0
    # via nbconvert
jupyterlab-server==2.27.3
    # via jupyterlab
jupyterlab-widgets==3.0.11
    # via ipywidgets
keras==3.4.1
    # via
    #   tensorflow
    #   tensorflow-cpu
kiwisolver==1.4.5
    # via matplotlib
kmodes==0.12.2
    # via -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
lazy-loader==0.4
    # via scikit-image
libclang==18.1.1
    # via
    #   tensorflow
    #   tensorflow-cpu
lime==0.2.0.1
    # via -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
llama-cloud==0.0.9
    # via llama-index-indices-managed-llama-cloud
llama-index==0.10.55
    # via -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
llama-index-agent-openai==0.2.8
    # via
    #   llama-index
    #   llama-index-program-openai
llama-index-cli==0.1.12
    # via llama-index
llama-index-core==0.10.55
    # via
    #   llama-index
    #   llama-index-agent-openai
    #   llama-index-cli
    #   llama-index-embeddings-azure-openai
    #   llama-index-embeddings-huggingface
    #   llama-index-embeddings-instructor
    #   llama-index-embeddings-openai
    #   llama-index-indices-managed-llama-cloud
    #   llama-index-llms-anthropic
    #   llama-index-llms-azure-openai
    #   llama-index-llms-bedrock
    #   llama-index-llms-ollama
    #   llama-index-llms-openai
    #   llama-index-multi-modal-llms-openai
    #   llama-index-program-openai
    #   llama-index-question-gen-openai
    #   llama-index-readers-file
    #   llama-index-readers-llama-parse
    #   llama-index-vector-stores-milvus
    #   llama-parse
llama-index-embeddings-azure-openai==0.1.10
    # via -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
llama-index-embeddings-huggingface==0.2.2
    # via -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
llama-index-embeddings-instructor==0.1.3
    # via -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
llama-index-embeddings-openai==0.1.10
    # via
    #   llama-index
    #   llama-index-cli
    #   llama-index-embeddings-azure-openai
llama-index-indices-managed-llama-cloud==0.2.5
    # via llama-index
llama-index-legacy==0.9.48
    # via llama-index
llama-index-llms-anthropic==0.1.15
    # via llama-index-llms-bedrock
llama-index-llms-azure-openai==0.1.8
    # via
    #   -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
    #   llama-index-embeddings-azure-openai
llama-index-llms-bedrock==0.1.12
    # via -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
llama-index-llms-ollama==0.1.5
    # via -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
llama-index-llms-openai==0.1.25
    # via
    #   -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
    #   llama-index
    #   llama-index-agent-openai
    #   llama-index-cli
    #   llama-index-llms-azure-openai
    #   llama-index-multi-modal-llms-openai
    #   llama-index-program-openai
    #   llama-index-question-gen-openai
llama-index-multi-modal-llms-openai==0.1.7
    # via llama-index
llama-index-program-openai==0.1.6
    # via
    #   llama-index
    #   llama-index-question-gen-openai
llama-index-question-gen-openai==0.1.3
    # via llama-index
llama-index-readers-file==0.1.30
    # via
    #   -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
    #   llama-index
llama-index-readers-llama-parse==0.1.6
    # via llama-index
llama-index-vector-stores-milvus==0.1.20
    # via -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
llama-parse==0.4.8
    # via llama-index-readers-llama-parse
llvmlite==0.43.0
    # via
    #   numba
    #   pynndescent
locket==1.0.0
    # via
    #   distributed
    #   partd
lxml==5.2.2
    # via python-pptx
mako==1.3.5
    # via alembic
markdown==3.6
    # via
    #   mlflow
    #   tensorboard
markdown-it-py==3.0.0
    # via rich
markupsafe==2.1.5
    # via
    #   jinja2
    #   mako
    #   nbconvert
    #   werkzeug
marshmallow==3.21.3
    # via
    #   dataclasses-json
    #   environs
matplotlib==3.9.1
    # via
    #   -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
    #   arviz
    #   bocd
    #   combo
    #   lime
    #   mlflow
    #   prophet
    #   pyod
    #   seaborn
    #   suod
matplotlib-inline==0.1.7
    # via
    #   ipykernel
    #   ipython
mdurl==0.1.2
    # via markdown-it-py
milvus-lite==2.4.8
    # via pymilvus
minijinja==2.0.1
    # via huggingface-hub
mistune==3.0.2
    # via nbconvert
ml-dtypes==0.4.0
    # via
    #   keras
    #   tensorflow
    #   tensorflow-cpu
mlflow==2.14.3
    # via -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
mpmath==1.3.0
    # via sympy
msal==1.30.0
    # via
    #   azure-identity
    #   msal-extensions
msal-extensions==1.2.0
    # via azure-identity
msgpack==1.0.8
    # via distributed
multidict==6.0.5
    # via
    #   aiohttp
    #   yarl
multipledispatch==1.0.0
    # via
    #   dask-glm
    #   dask-ml
    #   datashader
mypy-extensions==1.0.0
    # via typing-inspect
namex==0.0.8
    # via keras
nbclient==0.10.0
    # via nbconvert
nbconvert==7.16.4
    # via jupyter-server
nbdime==4.0.1
    # via jupyterlab-git
nbformat==5.10.4
    # via
    #   jupyter-server
    #   jupyterlab-git
    #   nbclient
    #   nbconvert
    #   nbdime
nest-asyncio==1.6.0
    # via
    #   ipykernel
    #   llama-index-core
    #   llama-index-legacy
networkx==3.2.1
    # via
    #   -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
    #   llama-index-core
    #   llama-index-legacy
    #   scikit-image
    #   torch
nltk==3.8.1
    # via
    #   llama-index-core
    #   llama-index-legacy
notebook-shim==0.2.4
    # via jupyterlab
numba==0.60.0
    # via
    #   combo
    #   dask-ml
    #   datashader
    #   pynndescent
    #   pyod
    #   shap
    #   sparse
    #   stumpy
    #   tslearn
    #   umap-learn
numpy==1.26.4
    # via
    #   -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
    #   arviz
    #   bocd
    #   bokeh
    #   cmdstanpy
    #   combo
    #   contourpy
    #   dask
    #   dask-ml
    #   datashader
    #   h5py
    #   imageio
    #   imbalanced-learn
    #   keras
    #   kmodes
    #   lime
    #   llama-index-core
    #   llama-index-legacy
    #   matplotlib
    #   ml-dtypes
    #   mlflow
    #   numba
    #   opt-einsum
    #   pandas
    #   patsy
    #   prophet
    #   pyarrow
    #   pymc3
    #   pyod
    #   rrcf
    #   scikit-image
    #   scikit-learn
    #   scipy
    #   seaborn
    #   sentence-transformers
    #   shap
    #   sparse
    #   stanio
    #   stumpy
    #   suod
    #   tensorboard
    #   tensorflow
    #   tensorflow-cpu
    #   theano-pymc
    #   tifffile
    #   transformers
    #   tslearn
    #   umap-learn
    #   xarray
    #   xarray-einstats
    #   xgboost
openai==1.35.14
    # via
    #   llama-index-agent-openai
    #   llama-index-core
    #   llama-index-legacy
opentelemetry-api==1.12.0
    # via
    #   mlflow
    #   opentelemetry-exporter-jaeger-thrift
    #   opentelemetry-exporter-otlp-proto-grpc
    #   opentelemetry-instrumentation
    #   opentelemetry-instrumentation-asgi
    #   opentelemetry-instrumentation-fastapi
    #   opentelemetry-propagator-b3
    #   opentelemetry-sdk
    #   splunk-opentelemetry
opentelemetry-exporter-jaeger-thrift==1.12.0
    # via splunk-opentelemetry
opentelemetry-exporter-otlp-proto-grpc==1.12.0
    # via splunk-opentelemetry
opentelemetry-instrumentation==0.33b0
    # via
    #   opentelemetry-instrumentation-asgi
    #   opentelemetry-instrumentation-fastapi
    #   splunk-opentelemetry
opentelemetry-instrumentation-asgi==0.33b0
    # via opentelemetry-instrumentation-fastapi
opentelemetry-instrumentation-fastapi==0.33b0
    # via -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
opentelemetry-propagator-b3==1.12.0
    # via splunk-opentelemetry
opentelemetry-proto==1.12.0
    # via opentelemetry-exporter-otlp-proto-grpc
opentelemetry-sdk==1.12.0
    # via
    #   mlflow
    #   opentelemetry-exporter-jaeger-thrift
    #   opentelemetry-exporter-otlp-proto-grpc
    #   splunk-opentelemetry
opentelemetry-semantic-conventions==0.33b0
    # via
    #   opentelemetry-instrumentation-asgi
    #   opentelemetry-instrumentation-fastapi
    #   opentelemetry-sdk
    #   splunk-opentelemetry
opentelemetry-util-http==0.33b0
    # via
    #   opentelemetry-instrumentation-asgi
    #   opentelemetry-instrumentation-fastapi
opt-einsum==3.3.0
    # via
    #   tensorflow
    #   tensorflow-cpu
optree==0.12.1
    # via keras
overrides==7.7.0
    # via jupyter-server
packaging==24.1
    # via
    #   arviz
    #   bokeh
    #   dask
    #   dask-ml
    #   datashader
    #   deprecation
    #   distributed
    #   gunicorn
    #   h5netcdf
    #   huggingface-hub
    #   ipykernel
    #   jupyter-server
    #   jupyterlab
    #   jupyterlab-git
    #   jupyterlab-server
    #   keras
    #   lazy-loader
    #   marshmallow
    #   matplotlib
    #   mlflow
    #   nbconvert
    #   scikit-image
    #   shap
    #   tensorflow
    #   tensorflow-cpu
    #   transformers
    #   xarray
pandas==2.2.2
    # via
    #   -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
    #   arviz
    #   bocd
    #   bokeh
    #   cmdstanpy
    #   dask
    #   dask-expr
    #   dask-ml
    #   datashader
    #   llama-index-core
    #   llama-index-legacy
    #   mlflow
    #   prophet
    #   pymc3
    #   pymilvus
    #   seaborn
    #   shap
    #   suod
    #   xarray
pandocfilters==1.5.1
    # via nbconvert
param==2.1.1
    # via
    #   datashader
    #   pyct
parso==0.8.4
    # via jedi
partd==1.4.2
    # via dask
patsy==0.5.6
    # via pymc3
pexpect==4.9.0
    # via
    #   ipython
    #   jupyterlab-git
pillow==10.4.0
    # via
    #   -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
    #   bokeh
    #   datashader
    #   imageio
    #   llama-index-core
    #   matplotlib
    #   python-pptx
    #   scikit-image
    #   sentence-transformers
platformdirs==4.2.2
    # via jupyter-core
portalocker==2.10.1
    # via msal-extensions
prometheus-client==0.20.0
    # via jupyter-server
prompt-toolkit==3.0.47
    # via ipython
prophet==1.1.5
    # via -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
protobuf==3.20.3
    # via
    #   googleapis-common-protos
    #   mlflow
    #   opentelemetry-proto
    #   pymilvus
    #   tensorboard
    #   tensorflow
    #   tensorflow-cpu
psutil==6.0.0
    # via
    #   distributed
    #   ipykernel
    #   suod
ptyprocess==0.7.0
    # via
    #   pexpect
    #   terminado
pure-eval==0.2.2
    # via stack-data
pyarrow==15.0.2
    # via
    #   dask-expr
    #   mlflow
pycparser==2.22
    # via cffi
pyct==0.5.0
    # via datashader
pydantic==2.8.2
    # via
    #   -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
    #   anthropic
    #   fastapi
    #   llama-cloud
    #   openai
pydantic-core==2.20.1
    # via pydantic
pygments==2.18.0
    # via
    #   ipython
    #   nbconvert
    #   nbdime
    #   rich
pyjwt[crypto]==2.8.0
    # via
    #   msal
    #   pyjwt
pymc3==3.11.4
    # via -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
pymilvus==2.4.4
    # via
    #   -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
    #   llama-index-vector-stores-milvus
pynndescent==0.5.13
    # via umap-learn
pyod==2.0.1
    # via
    #   -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
    #   combo
    #   suod
pyopenssl==24.1.0
    # via -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
pyparsing==3.1.2
    # via matplotlib
pypdf==4.3.0
    # via llama-index-readers-file
pypdf2==3.0.1
    # via -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
python-dateutil==2.9.0.post0
    # via
    #   arrow
    #   botocore
    #   holidays
    #   jupyter-client
    #   matplotlib
    #   pandas
python-dotenv==1.0.1
    # via
    #   environs
    #   uvicorn
python-json-logger==2.0.7
    # via jupyter-events
python-multipart==0.0.9
    # via fastapi
python-pptx==0.6.23
    # via -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
pytz==2024.1
    # via
    #   mlflow
    #   pandas
pyyaml==6.0.1
    # via
    #   -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
    #   bokeh
    #   dask
    #   distributed
    #   huggingface-hub
    #   jupyter-events
    #   llama-index-core
    #   mlflow
    #   transformers
    #   uvicorn
pyzmq==26.0.3
    # via
    #   ipykernel
    #   jupyter-client
    #   jupyter-server
querystring-parser==1.2.4
    # via mlflow
referencing==0.35.1
    # via
    #   jsonschema
    #   jsonschema-specifications
    #   jupyter-events
regex==2024.5.15
    # via
    #   nltk
    #   tiktoken
    #   transformers
requests==2.32.3
    # via
    #   azure-core
    #   datashader
    #   docker
    #   huggingface-hub
    #   jupyterlab-server
    #   llama-index-core
    #   llama-index-legacy
    #   mlflow
    #   msal
    #   nbdime
    #   tensorflow
    #   tensorflow-cpu
    #   tiktoken
    #   transformers
rfc3339-validator==0.1.4
    # via
    #   jsonschema
    #   jupyter-events
rfc3986-validator==0.1.1
    # via
    #   jsonschema
    #   jupyter-events
rich==13.7.1
    # via
    #   keras
    #   typer
rpds-py==0.19.0
    # via
    #   jsonschema
    #   referencing
rrcf==0.4.4
    # via -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
s3transfer==0.10.2
    # via boto3
safetensors==0.4.3
    # via transformers
scikit-image==0.24.0
    # via lime
scikit-learn==1.5.1
    # via
    #   -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
    #   combo
    #   dask-glm
    #   dask-ml
    #   imbalanced-learn
    #   kmodes
    #   lime
    #   mlflow
    #   pynndescent
    #   pyod
    #   sentence-transformers
    #   shap
    #   suod
    #   tslearn
    #   umap-learn
scipy==1.13.1
    # via
    #   -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
    #   arviz
    #   bocd
    #   combo
    #   dask-glm
    #   dask-ml
    #   datashader
    #   imbalanced-learn
    #   kmodes
    #   lime
    #   mlflow
    #   pymc3
    #   pynndescent
    #   pyod
    #   scikit-image
    #   scikit-learn
    #   sentence-transformers
    #   shap
    #   sparse
    #   stumpy
    #   suod
    #   theano-pymc
    #   tslearn
    #   umap-learn
    #   xarray-einstats
    #   xgboost
seaborn==0.13.2
    # via -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
semver==3.0.2
    # via pymc3
send2trash==1.8.3
    # via jupyter-server
sentence-transformers==2.7.0
    # via
    #   -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
    #   llama-index-embeddings-huggingface
    #   llama-index-embeddings-instructor
sentencepiece==0.2.0
    # via -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
shap==0.46.0
    # via -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
shellingham==1.5.4
    # via typer
simpervisor==1.0.0
    # via jupyter-server-proxy
six==1.16.0
    # via
    #   asttokens
    #   astunparse
    #   azure-core
    #   bleach
    #   google-pasta
    #   patsy
    #   python-dateutil
    #   querystring-parser
    #   rfc3339-validator
    #   tensorboard
    #   tensorflow
    #   tensorflow-cpu
    #   thrift
slicer==0.0.8
    # via shap
smmap==5.0.1
    # via gitdb
sniffio==1.3.1
    # via
    #   anthropic
    #   anyio
    #   httpx
    #   openai
sortedcontainers==2.4.0
    # via distributed
soupsieve==2.5
    # via beautifulsoup4
sparse==0.15.4
    # via dask-glm
splunk-opentelemetry[all]==1.8.0
    # via -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
splunk-sdk==2.0.2
    # via -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
sqlalchemy[asyncio]==2.0.31
    # via
    #   alembic
    #   llama-index-core
    #   llama-index-legacy
    #   mlflow
sqlparse==0.5.1
    # via mlflow
stack-data==0.6.3
    # via ipython
stanio==0.5.1
    # via cmdstanpy
starlette==0.37.2
    # via fastapi
striprtf==0.0.26
    # via llama-index-readers-file
stumpy==1.13.0
    # via -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
suod==0.1.3
    # via -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
sympy==1.13.0
    # via torch
tblib==3.0.0
    # via distributed
tenacity==8.5.0
    # via
    #   llama-index-core
    #   llama-index-legacy
tensorboard==2.17.0
    # via
    #   tensorflow
    #   tensorflow-cpu
tensorboard-data-server==0.7.2
    # via tensorboard
tensorflow==2.17.0
    # via tf-keras
tensorflow-cpu==2.17.0
    # via -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
tensorflow-io-gcs-filesystem==0.37.1
    # via
    #   tensorflow
    #   tensorflow-cpu
termcolor==2.4.0
    # via
    #   tensorflow
    #   tensorflow-cpu
terminado==0.18.1
    # via
    #   jupyter-server
    #   jupyter-server-terminals
tf-keras==2.17.0
    # via -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
theano-pymc==1.1.2
    # via pymc3
threadpoolctl==3.5.0
    # via
    #   imbalanced-learn
    #   scikit-learn
thrift==0.20.0
    # via opentelemetry-exporter-jaeger-thrift
tifffile==2024.7.2
    # via scikit-image
tiktoken==0.7.0
    # via
    #   llama-index-core
    #   llama-index-legacy
tinycss2==1.3.0
    # via nbconvert
tokenizers==0.19.1
    # via
    #   anthropic
    #   transformers
tomli==2.0.1
    # via jupyterlab
toolz==0.12.1
    # via
    #   dask
    #   datashader
    #   distributed
    #   partd
torch==2.3.1+cpu
    # via
    #   -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
    #   llama-index-embeddings-instructor
    #   sentence-transformers
tornado==6.4.1
    # via
    #   bokeh
    #   distributed
    #   ipykernel
    #   jupyter-client
    #   jupyter-server
    #   jupyter-server-proxy
    #   jupyterlab
    #   nbdime
    #   terminado
tqdm==4.66.4
    # via
    #   -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
    #   cmdstanpy
    #   huggingface-hub
    #   lime
    #   llama-index-core
    #   milvus-lite
    #   nltk
    #   openai
    #   prophet
    #   sentence-transformers
    #   shap
    #   transformers
    #   umap-learn
traitlets==5.14.3
    # via
    #   comm
    #   ipykernel
    #   ipython
    #   ipywidgets
    #   jupyter-client
    #   jupyter-core
    #   jupyter-events
    #   jupyter-server
    #   jupyter-server-proxy
    #   jupyterlab
    #   jupyterlab-git
    #   matplotlib-inline
    #   nbclient
    #   nbconvert
    #   nbformat
transformers==4.42.4
    # via sentence-transformers
tslearn==0.6.3
    # via -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
typer==0.12.3
    # via fastapi-cli
types-python-dateutil==2.9.0.20240316
    # via arrow
typing-extensions==4.12.2
    # via
    #   alembic
    #   anthropic
    #   anyio
    #   arviz
    #   asgiref
    #   async-lru
    #   azure-core
    #   azure-identity
    #   fastapi
    #   huggingface-hub
    #   ipython
    #   llama-index-core
    #   llama-index-legacy
    #   openai
    #   opentelemetry-sdk
    #   optree
    #   pydantic
    #   pydantic-core
    #   pymc3
    #   pypdf
    #   pypdf2
    #   sqlalchemy
    #   starlette
    #   tensorflow
    #   tensorflow-cpu
    #   torch
    #   typer
    #   typing-inspect
    #   uvicorn
typing-inspect==0.9.0
    # via
    #   dataclasses-json
    #   llama-index-core
    #   llama-index-legacy
tzdata==2024.1
    # via pandas
ujson==5.10.0
    # via pymilvus
umap-learn==0.5.6
    # via -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
uri-template==1.3.0
    # via jsonschema
urllib3==1.26.19
    # via
    #   botocore
    #   distributed
    #   docker
    #   requests
uvicorn[standard]==0.30.1
    # via
    #   -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
    #   fastapi
uvloop==0.19.0
    # via uvicorn
watchfiles==0.22.0
    # via uvicorn
wcwidth==0.2.13
    # via prompt-toolkit
webcolors==24.6.0
    # via jsonschema
webencodings==0.5.1
    # via
    #   bleach
    #   tinycss2
websocket-client==1.8.0
    # via jupyter-server
websockets==12.0
    # via uvicorn
werkzeug==3.0.3
    # via
    #   flask
    #   tensorboard
wheel==0.43.0
    # via astunparse
widgetsnbextension==4.0.11
    # via
    #   -r /temp/compiled_base_functional_specific_llm_rag_ubi-llm-rag.in
    #   ipywidgets
wrapt==1.16.0
    # via
    #   deprecated
    #   llama-index-core
    #   opentelemetry-instrumentation
    #   tensorflow
    #   tensorflow-cpu
xarray==2024.6.0
    # via
    #   arviz
    #   datashader
    #   xarray-einstats
xarray-einstats==0.7.0
    # via arviz
xgboost==0.90
    # via dask-xgboost
xlsxwriter==3.2.0
    # via python-pptx
xyzservices==2024.6.0
    # via bokeh
yarl==1.9.4
    # via aiohttp
zict==3.0.0
    # via distributed
zipp==3.19.2
    # via
    #   importlib-metadata
    #   importlib-resources

# The following packages are considered to be unsafe in a requirements file:
# setuptools
