{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splunk App for Data Science and Deep Learning - Neural Network Designer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network for Binary Classification with Dense Layers and Embeddings\n",
    "\n",
    "This notebook contains an example workflow how to work on custom containerized code that seamlessly interfaces with the Splunk App for Data Science and Deep Learning. As an example we use a custom binary neural network classifier built on keras and tensorflow. We refer to the TensorFlow tutorial for structured data with the feature columns feature: <a href=\"https://www.tensorflow.org/tutorials/structured_data/feature_columns\">https://www.tensorflow.org/tutorials/structured_data/feature_columns</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: By default every time you save this notebook the cells are exported into a python module which is then invoked by Splunk MLTK commands like <code> | fit ... | apply ... | summary </code>. Please read the Model Development Guide in the Deep Learning Toolkit app for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 0 - import libraries\n",
    "At stage 0 we define all imports necessary to run our subsequent code depending on various libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "name": "mltkc_import"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tensorflow/python/ops/random_ops.py:285: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  minval_is_zero = minval is 0  # pylint: disable=literal-comparison\n",
      "/opt/conda/lib/python3.8/site-packages/tensorflow/python/ops/random_ops.py:286: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  maxval_is_one = maxval is 1  # pylint: disable=literal-comparison\n",
      "/opt/conda/lib/python3.8/site-packages/tensorflow/python/ops/ragged/ragged_batch_gather_with_default_op.py:84: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if (default_value.shape.ndims is not 0\n",
      "/opt/conda/lib/python3.8/site-packages/tensorflow/python/ops/ragged/ragged_batch_gather_with_default_op.py:85: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  and default_value.shape.ndims is not 1):\n",
      "\"is not\" with a literal. Did you mean \"!=\"?\n",
      "\"is\" with a literal. Did you mean \"==\"?\n",
      "\"is\" with a literal. Did you mean \"==\"?\n",
      "\"is not\" with a literal. Did you mean \"!=\"?\n"
     ]
    }
   ],
   "source": [
    "# mltkc_import\n",
    "# this definition exposes all python module imports that should be available in all subsequent commands\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shap\n",
    "\n",
    "# restrict GPU memory https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "            # print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n",
    "# global constants\n",
    "MODEL_DIRECTORY = \"/srv/app/model/data/\"\n",
    "\n",
    "def df_to_dataset(dataframe, target_label_name, shuffle=True, batch_size=32):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop(target_label_name)\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds\n",
    "\n",
    "def df_to_dataset_apply(dataframe, batch_size=32):\n",
    "    dataframe = dataframe.copy()\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe)))\n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version: 1.19.2\n",
      "pandas version: 1.1.3\n",
      "TensorFlow version: 2.2.0\n",
      "Keras version: 2.3.0-tf\n",
      "SHAP version: 0.37.0\n"
     ]
    }
   ],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing purposes\n",
    "print(\"numpy version: \" + np.__version__)\n",
    "print(\"pandas version: \" + pd.__version__)\n",
    "print(\"TensorFlow version: \" + tf.__version__)\n",
    "print(\"Keras version: \" + keras.__version__)\n",
    "print(\"SHAP version: \" + shap.__version__)\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1 - get a data sample from Splunk\n",
    "In Splunk run a search to pipe a prepared dataset into this environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| inputlookup diabetic.csv <br>\n",
    "| eval _time = now() - random()%(3600*24) <br>\n",
    "| table _time * <br>\n",
    "| eval diabetesMed01 = if(diabetesMed==\"Yes\",1.0,0.0) <br>\n",
    "| fit MLTKContainer mode=stage algo=binary_nn_classifier_designer epochs=10 batch_size=4 structure=32-16 numeric_features=\"admission_source_id admission_type_id\" categorical_features=\"acetohexamide acarbose age\" embedding_features=\"\" diabetesMed01 from admission_source_id admission_type_id  acetohexamide acarbose age  into app:diabetes_med_model<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you run this search your data set sample is available as a csv inside the container to develop your model. The name is taken from the into keyword (\"my_model\" in the example above) or set to \"default\" if no into keyword is present. This step is intended to work with a subset of your data to create your custom model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "name": "mltkc_stage"
   },
   "outputs": [],
   "source": [
    "# mltkc_stage\n",
    "# this cell is not executed from MLTK and should only be used for staging data into the notebook environment\n",
    "def stage(name):\n",
    "    with open(\"data/\"+name+\".csv\", 'r') as f:\n",
    "        df = pd.read_csv(f)\n",
    "    with open(\"data/\"+name+\".json\", 'r') as f:\n",
    "        param = json.load(f)\n",
    "    return df, param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 6)\n",
      "{'options': {'params': {'mode': 'stage', 'algo': 'binary_nn_classifier_designer', 'epochs': '10', 'batch_size': '4', 'structure': '32-16', 'numeric_features': '\"admission_source_id admission_type_id\"', 'categorical_features': '\"acetohexamide acarbose age\"', 'embedding_features': '\"\"'}, 'args': ['diabetesMed01', 'admission_source_id', 'admission_type_id', 'acetohexamide', 'acarbose', 'age'], 'target_variable': ['diabetesMed01'], 'feature_variables': ['admission_source_id', 'admission_type_id', 'acetohexamide', 'acarbose', 'age'], 'model_name': 'diabetes_med_model', 'algo_name': 'MLTKContainer', 'mlspl_limits': {'handle_new_cat': 'default', 'max_distinct_cat_values': '100', 'max_distinct_cat_values_for_classifiers': '100', 'max_distinct_cat_values_for_scoring': '100', 'max_fit_time': '600', 'max_inputs': '100000', 'max_memory_usage_mb': '4000', 'max_model_size_mb': '30', 'max_score_time': '600', 'use_sampling': 'true'}, 'kfold_cv': None}, 'feature_variables': ['admission_source_id', 'admission_type_id', 'acetohexamide', 'acarbose', 'age'], 'target_variables': ['diabetesMed01']}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>acetohexamide</th>\n",
       "      <th>acarbose</th>\n",
       "      <th>diabetesMed01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0-10)</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[10-20)</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[20-30)</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[30-40)</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[40-50)</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>[80-90)</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>[80-90)</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>[50-60)</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>[50-60)</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>[80-90)</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age  admission_type_id  admission_source_id acetohexamide acarbose  \\\n",
       "0      [0-10)                  6                    1            No       No   \n",
       "1     [10-20)                  1                    7            No       No   \n",
       "2     [20-30)                  1                    7            No       No   \n",
       "3     [30-40)                  1                    7            No       No   \n",
       "4     [40-50)                  1                    7            No       No   \n",
       "...       ...                ...                  ...           ...      ...   \n",
       "9995  [80-90)                  5                   17            No       No   \n",
       "9996  [80-90)                  2                    1            No       No   \n",
       "9997  [50-60)                  1                    7            No       No   \n",
       "9998  [50-60)                  1                    7            No       No   \n",
       "9999  [80-90)                  1                   17            No       No   \n",
       "\n",
       "      diabetesMed01  \n",
       "0               0.0  \n",
       "1               1.0  \n",
       "2               1.0  \n",
       "3               1.0  \n",
       "4               1.0  \n",
       "...             ...  \n",
       "9995            1.0  \n",
       "9996            0.0  \n",
       "9997            0.0  \n",
       "9998            0.0  \n",
       "9999            1.0  \n",
       "\n",
       "[10000 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing purposes\n",
    "df, param = stage(\"diabetes_med_model\")\n",
    "print(df.shape)\n",
    "print(str(param))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2 - create and initialize a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "name": "mltkc_init"
   },
   "outputs": [],
   "source": [
    "# mltkc_init\n",
    "# initialize the model\n",
    "# params: data and parameters\n",
    "# returns the model object which will be used as a reference to call fit, apply and summary subsequently\n",
    "def init(df,param):\n",
    "    model = {}\n",
    "    model['param'] = param\n",
    "    #y = df[param['target_variables'][0]]\n",
    "    #X = df[param['feature_variables']] #.astype(float)\n",
    "    #print(\"FIT build model with input shape \" + str(X.shape))\n",
    "    #input_shape = int(X.shape[1])\n",
    "    \n",
    "    model_structure = '256-128'\n",
    "    numeric_features = None\n",
    "    embedding_features = None\n",
    "    embedding_dimensions = 8\n",
    "    categorical_features = None\n",
    "\n",
    "    feature_columns = []\n",
    "    \n",
    "    if 'options' in param:\n",
    "        if 'params' in param['options']:\n",
    "            if 'structure' in param['options']['params']:\n",
    "                model_structure = str(param['options']['params']['structure']).lstrip(\"\\\"\").rstrip(\"\\\"\").lstrip(\" \").rstrip(\" \")\n",
    "            if 'numeric_features' in param['options']['params']:\n",
    "                numeric_features = str(param['options']['params']['numeric_features']).lstrip(\"\\\"\").rstrip(\"\\\"\").lstrip(\" \").rstrip(\" \").replace(\" \", \",\").split(\",\")\n",
    "                for feature in numeric_features:\n",
    "                    if '*' in feature:\n",
    "                        wildcards = df.filter(like=feature.replace('*','')).columns\n",
    "                        for wildcard in wildcards:\n",
    "                            feature_columns.append(feature_column.numeric_column(wildcard))\n",
    "                    elif feature in df:\n",
    "                        feature_columns.append(feature_column.numeric_column(feature))\n",
    "            if 'embedding_features' in param['options']['params']:\n",
    "                embedding_features = str(param['options']['params']['embedding_features']).lstrip(\"\\\"\").rstrip(\"\\\"\").lstrip(\" \").rstrip(\" \").replace(\" \", \",\").split(\",\")\n",
    "                for feature in embedding_features:\n",
    "                    if '*' in feature:\n",
    "                        wildcards = df.filter(like=feature.replace('*','')).columns\n",
    "                        for wildcard in wildcards:\n",
    "                            feature_embedding = feature_column.categorical_column_with_vocabulary_list(wildcard, df[wildcard].unique())\n",
    "                            feature_embedding = feature_column.embedding_column(feature_embedding, dimension=embedding_dimensions)\n",
    "                            feature_columns.append(feature_embedding)\n",
    "                    elif feature in df:\n",
    "                        feature_embedding = feature_column.categorical_column_with_vocabulary_list(feature, df[feature].unique())\n",
    "                        feature_embedding = feature_column.embedding_column(feature_embedding, dimension=embedding_dimensions)\n",
    "                        feature_columns.append(feature_embedding)\n",
    "            if 'categorical_features' in param['options']['params']:\n",
    "                categorical_features = str(param['options']['params']['categorical_features']).lstrip(\"\\\"\").rstrip(\"\\\"\").lstrip(\" \").rstrip(\" \").replace(\" \", \",\").split(\",\")\n",
    "                for feature in categorical_features:\n",
    "                    if '*' in feature:\n",
    "                        wildcards = df.filter(like=feature.replace('*','')).columns\n",
    "                        for wildcard in wildcards:\n",
    "                            categorical_column = feature_column.categorical_column_with_vocabulary_list(wildcard, df[wildcard].unique())\n",
    "                            categorical_column = feature_column.indicator_column(categorical_column)\n",
    "                            feature_columns.append(categorical_column)\n",
    "                    elif feature in df:\n",
    "                        categorical_column = feature_column.categorical_column_with_vocabulary_list(feature, df[feature].unique())\n",
    "                        categorical_column = feature_column.indicator_column(categorical_column)\n",
    "                        feature_columns.append(categorical_column)\n",
    "                    \n",
    "    model['feature_columns'] = feature_columns\n",
    "    feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n",
    "    model['feature_layer'] = feature_layer\n",
    "    \n",
    "    hidden_factors = np.floor(np.array(model_structure.split(\"-\"), dtype=\"float\"))\n",
    "    keras_model = tf.keras.Sequential()\n",
    "    keras_model.add(feature_layer)\n",
    "    for hidden in hidden_factors:\n",
    "        keras_model.add(layers.Dense(int(hidden), activation=tf.nn.relu))\n",
    "        keras_model.add(layers.Dropout(0.01))\n",
    "    keras_model.add(layers.Dense(1, activation=tf.nn.sigmoid))\n",
    "        \n",
    "    keras_model.compile(optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    model['keras_model'] = keras_model\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test mltkc_stage_create_model\n",
    "model = init(df,param)\n",
    "#print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NumericColumn(key='admission_source_id', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='admission_type_id', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='acetohexamide', vocabulary_list=('No',), dtype=tf.string, default_value=-1, num_oov_buckets=0)), IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='acarbose', vocabulary_list=('No', 'Steady', 'Up'), dtype=tf.string, default_value=-1, num_oov_buckets=0)), IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='age', vocabulary_list=('[0-10)', '[10-20)', '[20-30)', '[30-40)', '[40-50)', '[50-60)', '[60-70)', '[70-80)', '[80-90)', '[90-100)'), dtype=tf.string, default_value=-1, num_oov_buckets=0))]\n"
     ]
    }
   ],
   "source": [
    "print(model['feature_columns'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3 - fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "name": "mltkc_fit"
   },
   "outputs": [],
   "source": [
    "# mltkc_stage_create_model_fit\n",
    "# returns a fit info json object\n",
    "def fit(model,df,param):\n",
    "    returns = {}\n",
    "    #X = df[param['feature_variables']]\n",
    "    #Y = df[param['target_variables']]\n",
    "    train, test = train_test_split(df, test_size=0.2)\n",
    "    train, val = train_test_split(train, test_size=0.2)\n",
    "    print(len(train), 'train examples')\n",
    "    print(len(val), 'validation examples')\n",
    "    print(len(test), 'test examples')\n",
    "        \n",
    "    model_epochs = 10\n",
    "    model_batch_size = 1\n",
    "    if 'options' in param:\n",
    "        if 'params' in param['options']:\n",
    "            if 'epochs' in param['options']['params']:\n",
    "                model_epochs = int(param['options']['params']['epochs'])\n",
    "            if 'batch_size' in param['options']['params']:\n",
    "                model_batch_size = int(param['options']['params']['batch_size'])\n",
    "    \n",
    "    train_ds = df_to_dataset(df, param['target_variables'][0], batch_size=model_batch_size)\n",
    "    val_ds = df_to_dataset(val, param['target_variables'][0], shuffle=False, batch_size=model_batch_size)\n",
    "    test_ds = df_to_dataset(test, param['target_variables'][0], shuffle=False, batch_size=model_batch_size)\n",
    "\n",
    "    # connect model training to tensorboard\n",
    "    log_dir=\"/srv/notebooks/logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    \n",
    "    # run the training\n",
    "    returns['fit_history'] = model['keras_model'].fit(train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=model_epochs,\n",
    "        verbose=2,\n",
    "        callbacks=[tensorboard_callback])    \n",
    "\n",
    "    returns['model_epochs'] = model_epochs\n",
    "    returns['model_batch_size'] = model_batch_size\n",
    "    model['model_epochs'] = model_epochs\n",
    "    model['model_batch_size'] = model_batch_size\n",
    "    \n",
    "    returns['model_loss_acc'] = model['keras_model'].evaluate(test_ds)\n",
    "    return returns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400 train examples\n",
      "1600 validation examples\n",
      "2000 test examples\n",
      "Epoch 1/10\n",
      "2500/2500 - 8s - loss: 0.5798 - accuracy: 0.7408 - val_loss: 0.5675 - val_accuracy: 0.7437\n",
      "Epoch 2/10\n",
      "2500/2500 - 7s - loss: 0.5713 - accuracy: 0.7410 - val_loss: 0.5641 - val_accuracy: 0.7437\n",
      "Epoch 3/10\n",
      "2500/2500 - 10s - loss: 0.5666 - accuracy: 0.7417 - val_loss: 0.5644 - val_accuracy: 0.7437\n",
      "Epoch 4/10\n",
      "2500/2500 - 8s - loss: 0.5653 - accuracy: 0.7417 - val_loss: 0.5745 - val_accuracy: 0.7444\n",
      "Epoch 5/10\n",
      "2500/2500 - 10s - loss: 0.5659 - accuracy: 0.7430 - val_loss: 0.5588 - val_accuracy: 0.7450\n",
      "Epoch 6/10\n",
      "2500/2500 - 9s - loss: 0.5639 - accuracy: 0.7418 - val_loss: 0.5587 - val_accuracy: 0.7456\n",
      "Epoch 7/10\n",
      "2500/2500 - 7s - loss: 0.5635 - accuracy: 0.7424 - val_loss: 0.5601 - val_accuracy: 0.7456\n",
      "Epoch 8/10\n",
      "2500/2500 - 7s - loss: 0.5631 - accuracy: 0.7423 - val_loss: 0.5578 - val_accuracy: 0.7456\n",
      "Epoch 9/10\n",
      "2500/2500 - 11s - loss: 0.5619 - accuracy: 0.7427 - val_loss: 0.5568 - val_accuracy: 0.7456\n",
      "Epoch 10/10\n",
      "2500/2500 - 8s - loss: 0.5626 - accuracy: 0.7427 - val_loss: 0.5592 - val_accuracy: 0.7456\n",
      "500/500 [==============================] - 1s 3ms/step - loss: 0.5603 - accuracy: 0.7440\n",
      "[0.5603327751159668, 0.7440000176429749]\n"
     ]
    }
   ],
   "source": [
    "returns = fit(model,df,param)\n",
    "print(returns['model_loss_acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 4 - apply the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "name": "mltkc_apply"
   },
   "outputs": [],
   "source": [
    "# mltkc_stage_create_model_apply\n",
    "def apply(model,df,param):\n",
    "    X = df[param['feature_variables']]\n",
    "    model_batch_size = 1\n",
    "    print(\"APPLY PARAMS: \" + str(param))\n",
    "    if 'options' in param:\n",
    "        if 'params' in param['options']:\n",
    "            if 'batch_size' in param['options']['params']:\n",
    "                model_batch_size = int(param['options']['params']['batch_size'])\n",
    "    # TODO\n",
    "    apply_dataset = df_to_dataset_apply(X, batch_size=model_batch_size)\n",
    "    y_hat = model['keras_model'].predict(apply_dataset, verbose=1)\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPLY PARAMS: {'options': {'params': {'mode': 'stage', 'algo': 'binary_nn_classifier_designer', 'epochs': '10', 'batch_size': '4', 'structure': '32-16', 'numeric_features': '\"admission_source_id admission_type_id\"', 'categorical_features': '\"acetohexamide acarbose age\"', 'embedding_features': '\"\"'}, 'args': ['diabetesMed01', 'admission_source_id', 'admission_type_id', 'acetohexamide', 'acarbose', 'age'], 'target_variable': ['diabetesMed01'], 'feature_variables': ['admission_source_id', 'admission_type_id', 'acetohexamide', 'acarbose', 'age'], 'model_name': 'diabetes_med_model', 'algo_name': 'MLTKContainer', 'mlspl_limits': {'handle_new_cat': 'default', 'max_distinct_cat_values': '100', 'max_distinct_cat_values_for_classifiers': '100', 'max_distinct_cat_values_for_scoring': '100', 'max_fit_time': '600', 'max_inputs': '100000', 'max_memory_usage_mb': '4000', 'max_model_size_mb': '30', 'max_score_time': '600', 'use_sampling': 'true'}, 'kfold_cv': None}, 'feature_variables': ['admission_source_id', 'admission_type_id', 'acetohexamide', 'acarbose', 'age'], 'target_variables': ['diabetesMed01']}\n",
      "2500/2500 [==============================] - 4s 2ms/step\n",
      "[[0.81771153]\n",
      " [0.96108097]\n",
      " [0.8631502 ]\n",
      " ...\n",
      " [0.77040887]\n",
      " [0.77040887]\n",
      " [0.84362054]]\n"
     ]
    }
   ],
   "source": [
    "# test mltkc_stage_create_model_apply\n",
    "y_hat = apply(model,df,param)\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 5 - save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "name": "mltkc_save"
   },
   "outputs": [],
   "source": [
    "# save model to name in expected convention \"<algo_name>_<model_name>.h5\"\n",
    "def save(model,name):\n",
    "    # save keras model to hdf5 file\n",
    "    # https://www.tensorflow.org/beta/tutorials/keras/save_and_restore_models\n",
    "    if 'keras_model' in model:\n",
    "        tf.keras.models.save_model(model['keras_model'], MODEL_DIRECTORY + name)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:1813: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: /srv/app/model/data/diabetes_med_model/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'param': {'options': {'params': {'mode': 'stage',\n",
       "    'algo': 'binary_nn_classifier_designer',\n",
       "    'epochs': '10',\n",
       "    'batch_size': '4',\n",
       "    'structure': '32-16',\n",
       "    'numeric_features': '\"admission_source_id admission_type_id\"',\n",
       "    'categorical_features': '\"acetohexamide acarbose age\"',\n",
       "    'embedding_features': '\"\"'},\n",
       "   'args': ['diabetesMed01',\n",
       "    'admission_source_id',\n",
       "    'admission_type_id',\n",
       "    'acetohexamide',\n",
       "    'acarbose',\n",
       "    'age'],\n",
       "   'target_variable': ['diabetesMed01'],\n",
       "   'feature_variables': ['admission_source_id',\n",
       "    'admission_type_id',\n",
       "    'acetohexamide',\n",
       "    'acarbose',\n",
       "    'age'],\n",
       "   'model_name': 'diabetes_med_model',\n",
       "   'algo_name': 'MLTKContainer',\n",
       "   'mlspl_limits': {'handle_new_cat': 'default',\n",
       "    'max_distinct_cat_values': '100',\n",
       "    'max_distinct_cat_values_for_classifiers': '100',\n",
       "    'max_distinct_cat_values_for_scoring': '100',\n",
       "    'max_fit_time': '600',\n",
       "    'max_inputs': '100000',\n",
       "    'max_memory_usage_mb': '4000',\n",
       "    'max_model_size_mb': '30',\n",
       "    'max_score_time': '600',\n",
       "    'use_sampling': 'true'},\n",
       "   'kfold_cv': None},\n",
       "  'feature_variables': ['admission_source_id',\n",
       "   'admission_type_id',\n",
       "   'acetohexamide',\n",
       "   'acarbose',\n",
       "   'age'],\n",
       "  'target_variables': ['diabetesMed01']},\n",
       " 'feature_columns': [NumericColumn(key='admission_source_id', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       "  NumericColumn(key='admission_type_id', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       "  IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='acetohexamide', vocabulary_list=('No',), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
       "  IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='acarbose', vocabulary_list=('No', 'Steady', 'Up'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
       "  IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='age', vocabulary_list=('[0-10)', '[10-20)', '[20-30)', '[30-40)', '[40-50)', '[50-60)', '[60-70)', '[70-80)', '[80-90)', '[90-100)'), dtype=tf.string, default_value=-1, num_oov_buckets=0))],\n",
       " 'feature_layer': <tensorflow.python.feature_column.dense_features_v2.DenseFeatures at 0x7f1642057400>,\n",
       " 'keras_model': <tensorflow.python.keras.engine.sequential.Sequential at 0x7f16b2570d60>,\n",
       " 'model_epochs': 10,\n",
       " 'model_batch_size': 4}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save(model,'diabetes_med_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 6 - load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "name": "mltkc_load"
   },
   "outputs": [],
   "source": [
    "# load model from name in expected convention \"<algo_name>_<model_name>.h5\"\n",
    "def load(name):\n",
    "    model = {}\n",
    "    #with open(MODEL_DIRECTORY + name + \".feature_layer_config.json\", 'r') as file:\n",
    "    #    feature_layer_config = json.load(file)\n",
    "\n",
    "    # #model = tf.keras.models.load_model(MODEL_DIRECTORY + name + '.h5') #, custom_objects=feature_layer_config)\n",
    "    model['keras_model'] = tf.keras.models.load_model(MODEL_DIRECTORY + name)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = load('diabetes_med_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPLY PARAMS: {'options': {'params': {'mode': 'stage', 'algo': 'binary_nn_classifier_designer', 'epochs': '10', 'batch_size': '4', 'structure': '32-16', 'numeric_features': '\"admission_source_id admission_type_id\"', 'categorical_features': '\"acetohexamide acarbose age\"', 'embedding_features': '\"\"'}, 'args': ['diabetesMed01', 'admission_source_id', 'admission_type_id', 'acetohexamide', 'acarbose', 'age'], 'target_variable': ['diabetesMed01'], 'feature_variables': ['admission_source_id', 'admission_type_id', 'acetohexamide', 'acarbose', 'age'], 'model_name': 'diabetes_med_model', 'algo_name': 'MLTKContainer', 'mlspl_limits': {'handle_new_cat': 'default', 'max_distinct_cat_values': '100', 'max_distinct_cat_values_for_classifiers': '100', 'max_distinct_cat_values_for_scoring': '100', 'max_fit_time': '600', 'max_inputs': '100000', 'max_memory_usage_mb': '4000', 'max_model_size_mb': '30', 'max_score_time': '600', 'use_sampling': 'true'}, 'kfold_cv': None}, 'feature_variables': ['admission_source_id', 'admission_type_id', 'acetohexamide', 'acarbose', 'age'], 'target_variables': ['diabetesMed01']}\n",
      "2500/2500 [==============================] - 5s 2ms/step\n",
      "[[0.81771153]\n",
      " [0.96108097]\n",
      " [0.8631502 ]\n",
      " ...\n",
      " [0.77040887]\n",
      " [0.77040887]\n",
      " [0.84362054]]\n"
     ]
    }
   ],
   "source": [
    "y_hat = apply(model2,df,param)\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 7 - provide a summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "name": "mltkc_summary"
   },
   "outputs": [],
   "source": [
    "# return model summary\n",
    "def summary(model=None):\n",
    "    returns = {\"version\": {\"tensorflow\": tf.__version__, \"keras\": keras.__version__} }\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Stages\n",
    "All subsequent cells are not tagged and can be used for further freeform code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'version': {'tensorflow': '2.2.0', 'keras': '2.3.0-tf'}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
