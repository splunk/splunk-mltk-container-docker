{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ollama Model Manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook allows you to manage LLM models on your Ollama deployment through a simple FIT command. Specify task=pull to download and task=delete to delete models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example usage:\n",
    "| makeresults | fit MLTKContainer algo=llm_rag_ollama_model_manager task=pull model_name=mistral _time into app:llm_rag_ollama_model_manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 0 - import libraries\n",
    "At stage 0 we define all imports necessary to run our subsequent code depending on various libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "name": "mltkc_import"
   },
   "outputs": [],
   "source": [
    "# this definition exposes all python module imports that should be available in all subsequent commands\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "# ...\n",
    "# global constants\n",
    "ollama_url = \"http://ollama:11434\"\n",
    "MODEL_DIRECTORY = \"/srv/app/model/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1 - get a data sample from Splunk\n",
    "In Splunk run a search to pipe a dataset into your notebook environment. Note: mode=stage is used in the | fit command to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you run this search your data set sample is available as a csv inside the container to develop your model. The name is taken from the into keyword (\"barebone_model\" in the example above) or set to \"default\" if no into keyword is present. This step is intended to work with a subset of your data to create your custom model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "name": "mltkc_stage"
   },
   "outputs": [],
   "source": [
    "# this cell is not executed from MLTK and should only be used for staging data into the notebook environment\n",
    "def stage(name):\n",
    "    with open(\"data/\"+name+\".csv\", 'r') as f:\n",
    "        df = pd.read_csv(f)\n",
    "    with open(\"data/\"+name+\".json\", 'r') as f:\n",
    "        param = json.load(f)\n",
    "    return df, param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              _time\n",
      "count  1.000000e+00\n",
      "mean   1.715575e+09\n",
      "std             NaN\n",
      "min    1.715575e+09\n",
      "25%    1.715575e+09\n",
      "50%    1.715575e+09\n",
      "75%    1.715575e+09\n",
      "max    1.715575e+09\n",
      "{'options': {'params': {'mode': 'stage', 'algo': 'ollama_model_manager', 'manager': 'pull', 'model': 'mistral'}, 'args': ['_time'], 'feature_variables': ['_time'], 'model_name': 'ollama_model_manager', 'algo_name': 'MLTKContainer', 'mlspl_limits': {'disabled': False, 'handle_new_cat': 'default', 'max_distinct_cat_values': '100', 'max_distinct_cat_values_for_classifiers': '100', 'max_distinct_cat_values_for_scoring': '100', 'max_fit_time': '60000', 'max_inputs': '100000', 'max_memory_usage_mb': '4000', 'max_model_size_mb': '30', 'max_score_time': '600', 'use_sampling': '1'}, 'kfold_cv': None}, 'feature_variables': ['_time']}\n"
     ]
    }
   ],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing or development purposes\n",
    "df, param = stage(\"llm_rag_ollama_model_manager\")\n",
    "print(df.describe())\n",
    "print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2 - create and initialize a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "name": "mltkc_init"
   },
   "outputs": [],
   "source": [
    "# initialize your model\n",
    "# available inputs: data and parameters\n",
    "# returns the model object which will be used as a reference to call fit, apply and summary subsequently\n",
    "def init(df,param):\n",
    "    model = {}\n",
    "    model['hyperparameter'] = 42.0\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing or development purposes\n",
    "print(init(df,param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3 - fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "name": "mltkc_fit"
   },
   "outputs": [],
   "source": [
    "# train your model\n",
    "# returns a fit info json object and may modify the model object\n",
    "def fit(model,df,param):\n",
    "    # model.fit()\n",
    "    info = {\"message\": \"model trained\"}\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing or development purposes\n",
    "print(fit(model,df,param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 4 - apply the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "name": "mltkc_apply"
   },
   "outputs": [],
   "source": [
    "def apply(model,df,param):\n",
    "    manager = param['options']['params']['task'].strip('\\\"')\n",
    "    try:\n",
    "        model_type = param['options']['params']['model_type'].strip('\\\"')\n",
    "    except:\n",
    "        model_type = \"LLM\"\n",
    "    if model_type == \"embedder_model\":\n",
    "        # embedder model\n",
    "        if manager == \"pull\":\n",
    "            model_name = param['options']['params']['model_name'].strip('\\\"').strip('\\'')\n",
    "            if model_name == "all-MiniLM-L6-v2" or model_name == "intfloat/multilingual-e5-large":\n",
    "                modelPath = os.path.join(\"/srv/app/model/data\", model_name)\n",
    "                try:\n",
    "                    os.makedirs(modelPath)\n",
    "                except:\n",
    "                    print(\"path already exists\")\n",
    "                model = SentenceTransformer(model_name)\n",
    "                model.save(modelPath)\n",
    "                l = model_name\n",
    "                m = f\"Downloaded embedder model {model_name}\"\n",
    "            else:\n",
    "                print(\"Model Not supported\")\n",
    "                l = \"None\"\n",
    "                m = \"Not supported model\"\n",
    "        else:\n",
    "            print(\"Not supported\")\n",
    "            l = \"None\"\n",
    "            m = \"Not supported task\"\n",
    "    else:\n",
    "        if manager == \"pull\":\n",
    "            # Download specified model\n",
    "            try:\n",
    "                model_name = param['options']['params']['model_name'].strip('\\\"')\n",
    "                uri = f\"{ollama_url}/api/pull\"\n",
    "                data = {\n",
    "                    \"name\": model_name\n",
    "                }\n",
    "                data = json.dumps(data)\n",
    "                requests.post(uri, data=data)\n",
    "                m = f'Pulled model {model_name}.'\n",
    "            except:\n",
    "                m = f'ERROR during model download.'\n",
    "            \n",
    "        elif manager == \"delete\":\n",
    "            # Delete specified model\n",
    "            model_name = param['options']['params']['model_name'].strip('\\\"')\n",
    "            uri = f\"{ollama_url}/api/delete\"\n",
    "            data = {\n",
    "                \"name\": model_name\n",
    "            }\n",
    "            data = json.dumps(data)\n",
    "            requests.delete(uri, data=data)\n",
    "            m = f'Deleted model {model_name}.'\n",
    "        else:\n",
    "            m = \"No task specified\"\n",
    "        \n",
    "        # List all existing models    \n",
    "        uri = f\"{ollama_url}/api/tags\"\n",
    "        response = requests.get(uri).json()\n",
    "        response = response['models']\n",
    "        try:\n",
    "            l = \"\"\n",
    "            for r in response:\n",
    "                l += r['model'].split(\":\")[0]\n",
    "                l += \" \"\n",
    "        except:\n",
    "            l = None\n",
    "    l = [l]\n",
    "    m = [m]\n",
    "    cols={'Models': l, 'Message': m}\n",
    "    returns=pd.DataFrame(data=cols)\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing or development purposes\n",
    "print(apply(model,df,param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 5 - save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "name": "mltkc_save"
   },
   "outputs": [],
   "source": [
    "# save model to name in expected convention \"<algo_name>_<model_name>\"\n",
    "def save(model,name):\n",
    "    with open(MODEL_DIRECTORY + name + \".json\", 'w') as file:\n",
    "        json.dump(model, file)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 6 - load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "name": "mltkc_load"
   },
   "outputs": [],
   "source": [
    "# load model from name in expected convention \"<algo_name>_<model_name>\"\n",
    "def load(name):\n",
    "    model = {}\n",
    "    with open(MODEL_DIRECTORY + name + \".json\", 'r') as file:\n",
    "        model = json.load(file)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 7 - provide a summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "name": "mltkc_summary"
   },
   "outputs": [],
   "source": [
    "# return a model summary\n",
    "def summary(model=None):\n",
    "    returns = {\"version\": {\"numpy\": np.__version__, \"pandas\": pd.__version__} }\n",
    "    return returns\n",
    "\n",
    "def compute(model,df,param):\n",
    "    manager = param['params']['task'].strip('\\\"')\n",
    "    try:\n",
    "        model_type = param['params']['model_type'].strip('\\\"')\n",
    "    except:\n",
    "        model_type = \"LLM\"\n",
    "    \n",
    "    if model_type == \"embedder_model\":\n",
    "        # embedder model\n",
    "        if manager == \"pull\":\n",
    "            model_name = param['params']['model_name'].strip('\\\"').strip('\\'')\n",
    "            modelPath = os.path.join(\"/srv/app/model/data\", model_name)\n",
    "            try:\n",
    "                os.makedirs(modelPath)\n",
    "            except:\n",
    "                print(\"path already exists\")\n",
    "            model = SentenceTransformer(model_name)\n",
    "            model.save(modelPath)\n",
    "            l = model_name\n",
    "            m = f\"Downloaded embedder model {model_name}\"\n",
    "        else:\n",
    "            print(\"Not supported\")\n",
    "            l = \"None\"\n",
    "            m = \"Not supported task\"\n",
    "                  \n",
    "    else:\n",
    "        # LLM model\n",
    "        if manager == \"pull\":\n",
    "            # Download specified model\n",
    "            try:\n",
    "                model_name = param['params']['model_name'].strip('\\\"')\n",
    "                uri = f\"{ollama_url}/api/pull\"\n",
    "                data = {\n",
    "                    \"name\": model_name\n",
    "                }\n",
    "                data = json.dumps(data)\n",
    "                requests.post(uri, data=data)\n",
    "                m = f'Pulled model {model_name}.'\n",
    "            except:\n",
    "                m = f'ERROR during model download.'\n",
    "            \n",
    "        elif manager == \"delete\":\n",
    "            # Delete specified model\n",
    "            model_name = param['params']['model_name'].strip('\\\"')\n",
    "            uri = f\"{ollama_url}/api/delete\"\n",
    "            data = {\n",
    "                \"name\": model_name\n",
    "            }\n",
    "            data = json.dumps(data)\n",
    "            requests.delete(uri, data=data)\n",
    "            m = f'Deleted model {model_name}.'\n",
    "        else:\n",
    "            m = \"No task specified\"\n",
    "        \n",
    "        # List all existing models    \n",
    "        uri = f\"{ollama_url}/api/tags\"\n",
    "        response = requests.get(uri).json()\n",
    "        response = response['models']\n",
    "        try:\n",
    "            l = \"\"\n",
    "            for r in response:\n",
    "                l += r['model'].split(\":\")[0]\n",
    "                l += \" \"\n",
    "        except:\n",
    "            l = None\n",
    "\n",
    "    cols={'Models': l, 'Message': m}\n",
    "    returns= [cols]\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After implementing your fit, apply, save and load you can train your model:<br>\n",
    "| makeresults count=10<br>\n",
    "| streamstats c as i<br>\n",
    "| eval s = i%3<br>\n",
    "| eval feature_{s}=0<br>\n",
    "| foreach feature_* [eval &lt;&lt;FIELD&gt;&gt;=random()/pow(2,31)]<br>\n",
    "| fit MLTKContainer algo=barebone s from feature_* into app:barebone_model<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or apply your model:<br>\n",
    "| makeresults count=10<br>\n",
    "| streamstats c as i<br>\n",
    "| eval s = i%3<br>\n",
    "| eval feature_{s}=0<br>\n",
    "| foreach feature_* [eval &lt;&lt;FIELD&gt;&gt;=random()/pow(2,31)]<br>\n",
    "| apply barebone_model as the_meaning_of_life"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Stages\n",
    "All subsequent cells are not tagged and can be used for further freeform code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
