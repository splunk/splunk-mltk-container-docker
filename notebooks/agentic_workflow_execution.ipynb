{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentic Workflow Execution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to execute Agentic Workflows defined in **agentic_workflows.ipynb**\n",
    "\n",
    "Required Parameters:\n",
    "- workflow_name: Name of the workflow to be executed\n",
    "- query: Input query of the workflow\n",
    "\n",
    "Example SPL:\n",
    "\n",
    "| makeresults\n",
    "| fit MLTKContainer algo=agentic_workflow_execution workflow_name=SimpleLLMFlow query=\"What does Splunk do?\" * into app:agentic_workflow_execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 0 - import libraries\n",
    "At stage 0 we define all imports necessary to run our subsequent code depending on various libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "name": "mltkc_import"
   },
   "outputs": [],
   "source": [
    "# this definition exposes all python module imports that should be available in all subsequent commands\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import importlib\n",
    "import asyncio\n",
    "import concurrent.futures\n",
    "\n",
    "# Run async agent in sync\n",
    "def run_async_in_sync(async_func):\n",
    "    loop = asyncio.get_event_loop()\n",
    "    if loop.is_running():\n",
    "        with concurrent.futures.ThreadPoolExecutor() as pool:\n",
    "            return pool.submit(lambda: asyncio.run(async_func())).result()\n",
    "    else:\n",
    "        return asyncio.run(async_func())\n",
    "# ...\n",
    "# global constants\n",
    "module_path = \"app.model.agentic_workflows\"\n",
    "MODEL_DIRECTORY = \"/srv/app/model/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version: 1.26.4\n",
      "pandas version: 2.2.0\n"
     ]
    }
   ],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing or development purposes\n",
    "print(\"numpy version: \" + np.__version__)\n",
    "print(\"pandas version: \" + pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1 - get a data sample from Splunk\n",
    "There are currently 2 ways to retrieve data from Splunk: Option 1 is to interactively pull data from Splunk into the DSDL Jupyter Lab environment. This is useful when the Splunk REST API is accessible from the Jupyter environment and a valid Splunk auth token is defined in the DSDL app. This option has advantages to quickly experiment with different Splunk SPL queries and further interactively work with the search results in Jupyter. Note that no meta data param object is retrieved here. This is only available in Stage 1 Option 2.\n",
    "\n",
    "### Option 1 - pull data from Splunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "name": "mltkc_stage"
   },
   "outputs": [],
   "source": [
    "# this cell is not executed from MLTK and should only be used for staging data into the notebook environment\n",
    "def stage(name):\n",
    "    with open(\"data/\"+name+\".csv\", 'r') as f:\n",
    "        df = pd.read_csv(f)\n",
    "    with open(\"data/\"+name+\".json\", 'r') as f:\n",
    "        param = json.load(f)\n",
    "    return df, param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing or development purposes\n",
    "df, param = stage(\"agentic_workflow_execution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2 - create and initialize a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "name": "mltkc_init"
   },
   "outputs": [],
   "source": [
    "# initialize your model\n",
    "# available inputs: data and parameters\n",
    "# returns the model object which will be used as a reference to call fit, apply and summary subsequently\n",
    "def init(df,param):\n",
    "    model = {}\n",
    "    model['hyperparameter'] = 42.0\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing or development purposes\n",
    "model = init(df,param)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3 - fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "name": "mltkc_fit"
   },
   "outputs": [],
   "source": [
    "# train your model\n",
    "# returns a fit info json object and may modify the model object\n",
    "def fit(model,df,param):\n",
    "    # model.fit()\n",
    "    info = {\"message\": \"model trained\"}\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing or development purposes\n",
    "print(fit(model,df,param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 4 - apply the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "name": "mltkc_apply"
   },
   "outputs": [],
   "source": [
    "# apply your model\n",
    "def apply(model,df,param):\n",
    "    try:\n",
    "        query = param['options']['params']['query'].strip('\\\"')\n",
    "    except:\n",
    "        result = pd.DataFrame({'Message': [\"ERROR: Please input a parameter \\'prompt\\'.\"]})\n",
    "        return result\n",
    "        \n",
    "    try:\n",
    "        workflow_name = param['options']['params']['workflow_name'].strip('\\\"')\n",
    "    except:\n",
    "        result = pd.DataFrame({'Message': [\"ERROR: Please input a parameter \\'workflow_name\\'.\"]})\n",
    "        return result\n",
    "        \n",
    "    try:\n",
    "        llm_utils_module = importlib.import_module(module_path)\n",
    "        dynamic_function = getattr(llm_utils_module, workflow_name)\n",
    "        print(f\"Successfully imported '{workflow_name}' from '{module_path}'.\")\n",
    "        print(f\"Type of dynamic_function: {type(dynamic_function)}\")\n",
    "\n",
    "        w = dynamic_function(timeout=6000, verbose=False)\n",
    "        async def agent_run():\n",
    "            # Run the agent\n",
    "            response = await w.run(query=query)\n",
    "            return response\n",
    "        output = run_async_in_sync(agent_run)\n",
    "        result = pd.DataFrame({'Response': [output]})\n",
    "        return result      \n",
    "    \n",
    "    except ImportError as e:\n",
    "        error = f\"Error importing module '{module_path}': {e}\"\n",
    "        result = pd.DataFrame({'Message': [error]})\n",
    "        return result\n",
    "    except AttributeError as e:\n",
    "        error = f\"Error finding attribute '{a}' in module '{module_path}': {e}\"\n",
    "        result = pd.DataFrame({'Message': [error]})\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        error = f\"An unexpected error occurred: {e}\"\n",
    "        result = pd.DataFrame({'Message': [error]})\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing or development purposes\n",
    "model = None\n",
    "df = pd.DataFrame({'Message': [\"test\"]})\n",
    "param = {'options':{'params': {'query': \"What is Splunk\", 'workflow_name': \"SimpleLLMFlow\"}}}\n",
    "d = apply(model,df,param)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 5 - save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "name": "mltkc_save"
   },
   "outputs": [],
   "source": [
    "# save model to name in expected convention \"<algo_name>_<model_name>\"\n",
    "def save(model,name):\n",
    "    with open(MODEL_DIRECTORY + name + \".json\", 'w') as file:\n",
    "        json.dump(model, file)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 6 - load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "name": "mltkc_load"
   },
   "outputs": [],
   "source": [
    "# load model from name in expected convention \"<algo_name>_<model_name>\"\n",
    "def load(name):\n",
    "    model = {}\n",
    "    with open(MODEL_DIRECTORY + name + \".json\", 'r') as file:\n",
    "        model = json.load(file)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 7 - provide a summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "name": "mltkc_summary"
   },
   "outputs": [],
   "source": [
    "# return a model summary\n",
    "def summary(model=None):\n",
    "    returns = {\"version\": {\"numpy\": np.__version__, \"pandas\": pd.__version__} }\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Stages\n",
    "All subsequent cells are not tagged and can be used for further freeform code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
