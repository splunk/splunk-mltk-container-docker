{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cisco Time Series Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook supports time series data forecasting algorithm based on Cisco Time Series Model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model checkpoint (available on huggingface) is downloaded automatically at first execution of this algorithm. \n",
    "After the initial download, the model will always be loaded from the local path /srv/app/model/data.\n",
    "\n",
    "To update model version, use the hf_repo parameter in the Fit command to download the updated model version.\n",
    "\n",
    "Example Fit command:\n",
    "\n",
    "\\<Search of time series data\\> | table _time Number | sort _time **| fit MLTKContainer algo=tsfm_forecast hf_repo=\"repo_name\" local_path=\"/srv/app/model/data/model.pt\" value_field=\"Number\" forecast_steps=128 * into app:tsfm_forecast**\n",
    "\n",
    "* MODEL LOADING PARAMETER OPTIONS\n",
    "  * hf_repo: The repo name to download the model. Will set to Splunk default repo if not specified\n",
    "  * local_path: (OPTIONAL) If you have downloaded the model checkpoint to your local path and would like to load it directly from local, input the path to the model file\n",
    "  * If non specified, it will download model from default Huggingface repo\n",
    "* value_field: The field name of the time series value from the search result\n",
    "* forecast_steps: Future steps to predict (minutes)\n",
    "\n",
    "The command will return a list of predicted value for each future step, including P10 to P90 and mean\n",
    "\n",
    "**NOTE**:\n",
    "* The model forecasting is conducted on existing timestamps from the input dataset based on the prediction_length (last steps of the time series).\n",
    "* To predict the future states of the time series, please pad the current time series data with future timestamps and assign 0 to the future time series values.\n",
    "* Refer to the exaple SPL below to see about the time series padding:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example SPL with timestamp padding:\n",
    "\n",
    "| inputlookup internet_traffic.csv | head 10000 | timechart span=5min avg(\"bits_transferred\") as bits_transferred\n",
    "| eval bits_transferred = bits_transferred / 1024 / 1024\n",
    "| sort _time\n",
    "\n",
    "```\n",
    "Adding data point padding to continue the timeseries for forecasting\n",
    "```\n",
    "| append [| makeresults count=128 | eval bits_transferred=0, _time = 0 | streamstats count as pad ]\n",
    "| eventstats latest(_time) as latest_timestamp\n",
    "| eval _time=if(pad>0, latest_timestamp + pad*300, _time)\n",
    "| table _time bits_transferred\n",
    "\n",
    "```\n",
    "Forecasting the padded time series with TSFM\n",
    "```\n",
    "| fit MLTKContainer algo=tsfm_forecast value_field=\"bits_transferred\" forecast_steps=128 * into app:tsfm_forecast\n",
    "| tail 5000\n",
    "| table _time bits_transferred predicted_*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 0 - import libraries\n",
    "At stage 0 we define all imports necessary to run our subsequent code depending on various libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "name": "mltkc_import"
   },
   "outputs": [],
   "source": [
    "# this definition exposes all python module imports that should be available in all subsequent commands\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm, trange\n",
    "from typing import List, Tuple\n",
    "import torch\n",
    "from datasets import Dataset as HFDataset\n",
    "from huggingface_hub import snapshot_download\n",
    "from app.model.patched_decoder_multi_resolution import PatchedTSMultiResolutionDecoder,TimesfmMRConfig\n",
    "from app.model.timesfm_multi_resolution import TimesFmMRTorch, TimesFmTorch\n",
    "from timesfm.pytorch_patched_decoder import create_quantiles\n",
    "from timesfm import TimesFmHparams, TimesFmCheckpoint\n",
    "# ...\n",
    "# global constants\n",
    "MODEL_DIRECTORY = \"/srv/app/model/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1 - get a data sample from Splunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "name": "mltkc_stage"
   },
   "outputs": [],
   "source": [
    "# this cell is not executed from MLTK and should only be used for staging data into the notebook environment\n",
    "def stage(name):\n",
    "    with open(\"data/\"+name+\".csv\", 'r') as f:\n",
    "        df = pd.read_csv(f)\n",
    "    with open(\"data/\"+name+\".json\", 'r') as f:\n",
    "        param = json.load(f)\n",
    "    return df, param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing or development purposes\n",
    "df, param = stage(\"tsfm_forecast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_time</th>\n",
       "      <th>bits_transferred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1118152800</td>\n",
       "      <td>3397.254111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1118153100</td>\n",
       "      <td>3538.337298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1118153400</td>\n",
       "      <td>3697.843268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1118153700</td>\n",
       "      <td>3696.780082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1118154000</td>\n",
       "      <td>4370.253163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1121151300</td>\n",
       "      <td>8144.962705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1121151600</td>\n",
       "      <td>8074.665832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1121151900</td>\n",
       "      <td>8217.367633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1121152200</td>\n",
       "      <td>7817.648371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1121152500</td>\n",
       "      <td>6881.589949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           _time  bits_transferred\n",
       "0     1118152800       3397.254111\n",
       "1     1118153100       3538.337298\n",
       "2     1118153400       3697.843268\n",
       "3     1118153700       3696.780082\n",
       "4     1118154000       4370.253163\n",
       "...          ...               ...\n",
       "9995  1121151300       8144.962705\n",
       "9996  1121151600       8074.665832\n",
       "9997  1121151900       8217.367633\n",
       "9998  1121152200       7817.648371\n",
       "9999  1121152500       6881.589949\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'options': {'params': {'mode': 'stage',\n",
       "   'algo': 'tsfm_forecast',\n",
       "   'value_field': '\"bits_transferred\"',\n",
       "   'forecast_steps': '128',\n",
       "   'local_path': '\"/srv/app/model/data/splunk--timeseries_foundation_model_v1/model.pt\"'},\n",
       "  'args': ['*'],\n",
       "  'feature_variables': ['*'],\n",
       "  'model_name': 'tsfm_forecast',\n",
       "  'algo_name': 'MLTKContainer',\n",
       "  'mlspl_limits': {'disabled': False,\n",
       "   'handle_new_cat': 'default',\n",
       "   'max_distinct_cat_values': '100',\n",
       "   'max_distinct_cat_values_for_classifiers': '100',\n",
       "   'max_distinct_cat_values_for_scoring': '100',\n",
       "   'max_fit_time': '600',\n",
       "   'max_inputs': '100000',\n",
       "   'max_memory_usage_mb': '4000',\n",
       "   'max_model_size_mb': '30',\n",
       "   'max_score_time': '600',\n",
       "   'use_sampling': '1'},\n",
       "  'kfold_cv': None},\n",
       " 'feature_variables': ['_time', 'bits_transferred']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2 - create and initialize a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "name": "mltkc_init"
   },
   "outputs": [],
   "source": [
    "# initialize your model\n",
    "# available inputs: data and parameters\n",
    "# returns the model object which will be used as a reference to call fit, apply and summary subsequently\n",
    "def init(df,param):\n",
    "    \n",
    "    hp = TimesFmHparams(\n",
    "        context_len=512,\n",
    "        horizon_len=128,\n",
    "        num_layers=50,\n",
    "        use_positional_embedding=False,\n",
    "        backend=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        hf_repo = param['options']['params']['hf_repo'].strip(\"\\\"\")\n",
    "    except:\n",
    "        # Need to change to correct default path\n",
    "        hf_repo = \"cisco-ai/cisco-time-series-model-1.0-preview\"\n",
    "\n",
    "    try:\n",
    "        local_path = param['options']['params']['local_path'].strip(\"\\\"\")\n",
    "    except:\n",
    "        local_path = None\n",
    "    print(local_path)\n",
    "    if local_path:\n",
    "        try:\n",
    "            print(local_path)\n",
    "            ckpt = TimesFmCheckpoint(path=local_path)\n",
    "            model_inst = TimesFmMRTorch(\n",
    "                hparams=hp,\n",
    "                checkpoint=ckpt,\n",
    "                use_multi_resolution=True,\n",
    "                use_special_token_s=True,\n",
    "            )\n",
    "        except:\n",
    "            # Load from Huggingface instead\n",
    "            ckpt = TimesFmCheckpoint(huggingface_repo_id=hf_repo)\n",
    "            model_inst = TimesFmMRTorch(\n",
    "                hparams=hp,\n",
    "                checkpoint=ckpt,\n",
    "                use_multi_resolution=True,\n",
    "                use_special_token_s=True,\n",
    "            )\n",
    "    else:\n",
    "        ckpt = TimesFmCheckpoint(huggingface_repo_id=hf_repo)\n",
    "        model_inst = TimesFmMRTorch(\n",
    "            hparams=hp,\n",
    "            checkpoint=ckpt,\n",
    "            use_multi_resolution=True,\n",
    "            use_special_token_s=True,\n",
    "        )\n",
    "\n",
    "    return model_inst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing or development purposes\n",
    "model = init(df,param)\n",
    "print(model._model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3 - fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "name": "mltkc_fit"
   },
   "outputs": [],
   "source": [
    "# train your model\n",
    "# returns a fit info json object and may modify the model object\n",
    "def fit(model,df,param):\n",
    "    # model.fit()\n",
    "    info = {\"message\": \"No model training required\"}\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': 'No model training required'}\n"
     ]
    }
   ],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing or development purposes\n",
    "print(fit(model,df,param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 4 - apply the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "name": "mltkc_apply"
   },
   "outputs": [],
   "source": [
    "# apply your model\n",
    "# returns the calculated results\n",
    "def apply(model,df,param):\n",
    "    try:\n",
    "        PREDICTION_LENGTH = int(param['options']['params']['forecast_steps'].strip(\"\\\"\"))\n",
    "    except:\n",
    "        PREDICTION_LENGTH = 128 \n",
    "    try:\n",
    "        value_field = param['options']['params']['value_field'].strip(\"\\\"\")\n",
    "    except:\n",
    "        cols={'Message': [\"ERROR: Please input parameter \\'value_field\\' indicating the value field of the time series data\"]}\n",
    "        returns=pd.DataFrame(data=cols)\n",
    "        return returns\n",
    "    try:\n",
    "        series_list = [df[value_field].values.tolist()[:-PREDICTION_LENGTH]]\n",
    "    except:\n",
    "        cols={'Message': [\"ERROR: Failed to load time series data. Make sure your value_field name is correct.\"]}\n",
    "        returns=pd.DataFrame(data=cols)\n",
    "        return returns\n",
    "        \n",
    "    # Aggregation factor for low-resolution (i.e. 1-min -> 60-min)\n",
    "    agg_factor = 60\n",
    "\n",
    "    # Inference for forecasting\n",
    "    mean, full = model.forecast(series_list, agg_factor=agg_factor)\n",
    "\n",
    "    # Obtain mean and quantiles of the forecasted series\n",
    "    means = series_list[0] + mean.tolist()[0]\n",
    "    p10 = series_list[0] + full[0,:,1].tolist() \n",
    "    p20 = series_list[0] + full[0,:,2].tolist() \n",
    "    p30 = series_list[0] + full[0,:,3].tolist() \n",
    "    p40 = series_list[0] + full[0,:,4].tolist() \n",
    "    p50 = series_list[0] + full[0,:,5].tolist() \n",
    "    p60 = series_list[0] + full[0,:,6].tolist() \n",
    "    p70 = series_list[0] + full[0,:,7].tolist() \n",
    "    p80 = series_list[0] + full[0,:,8].tolist() \n",
    "    p90 = series_list[0] + full[0,:,9].tolist() \n",
    "    \n",
    "    cols = {'mean': means, 'p10': p10, 'p20': p20, 'p30': p30, 'p40': p40, 'p50': p50, 'p60': p60, 'p70': p70, 'p80': p80, 'p90': p90}\n",
    "\n",
    "    result = pd.DataFrame(cols)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing or development purposes\n",
    "cols = apply(model,df,param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 5 - save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "name": "mltkc_save"
   },
   "outputs": [],
   "source": [
    "# save model to name in expected convention \"<algo_name>_<model_name>\"\n",
    "def save(model,name):\n",
    "    model = {}\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 6 - load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "name": "mltkc_load"
   },
   "outputs": [],
   "source": [
    "# load model from name in expected convention \"<algo_name>_<model_name>\"\n",
    "def load(name):\n",
    "    model = {}\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 7 - provide a summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "name": "mltkc_summary"
   },
   "outputs": [],
   "source": [
    "# return a model summary\n",
    "def summary(model=None):\n",
    "    returns = {\"version\": {\"numpy\": np.__version__, \"pandas\": pd.__version__} }\n",
    "    return returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Stages\n",
    "All subsequent cells are not tagged and can be used for further freeform code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
