{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding indexed data (log) from Splunk into vector DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example Usage: \n",
    "* Using default huggingface embedding:\n",
    "* * index=_internal error | table _raw sourcetype source | head 100 | fit MLTKContainer algo=llm_rag_log_encoder collection_name=\"test\" embedder_dimension=384 embedder_name=all-MiniLM-L6-v2 use_local=1 label_field_name=_raw * into app:llm_rag_log_encoder as Encode\n",
    "* Using Cloud-based embedding model\n",
    "* * index=_internal error | table _raw sourcetype source | head 100 | fit MLTKContainer algo=llm_rag_log_encoder collection_name=\"test2\" vectordb_service=milvus embedder_service=azure_openai embedder_dimension=3072 label_field_name=_raw * into app:llm_rag_log_encoder as Encode\n",
    " \n",
    "Parameters:\n",
    "* label_field_nam: The field of search result to encode.\n",
    "* collection_name: Name of the collection to store vectorized data.\n",
    "* vectordb_service: Type of VectorDB. Choose from milvus, pinecone, alloydb\n",
    "* embedder_service: Type of embedding model. Chose from huggingface, ollama, azure_openai, openai, bedrock, gemini\n",
    "* embedder_name: Name of embedding model. **OPTIONAl** if configured on DSDL UI.\n",
    "* embedder_dimension: Output dimensionality of the model. **OPTIONAl** if configured on DSDL UI."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 0 - import libraries\n",
    "At stage 0 we define all imports necessary to run our subsequent code depending on various libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "name": "mltkc_import",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this definition exposes all python module imports that should be available in all subsequent commands\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from llama_index.core import VectorStoreIndex, Document, StorageContext, ServiceContext, Settings\n",
    "from llama_index.vector_stores.milvus import MilvusVectorStore\n",
    "from app.model.llm_utils import create_llm, create_embedding_model, create_vector_db\n",
    "# ...\n",
    "# global constants\n",
    "MODEL_DIRECTORY = \"/srv/app/model/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing or development purposes\n",
    "print(\"numpy version: \" + np.__version__)\n",
    "print(\"pandas version: \" + pd.__version__)\n",
    "print(\"pymilvus version: \" + pymilvus.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "name": "mltkc_stage",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this cell is not executed from MLTK and should only be used for staging data into the notebook environment\n",
    "def stage(name):\n",
    "    with open(\"data/\"+name+\".csv\", 'r') as f:\n",
    "        df = pd.read_csv(f)\n",
    "    with open(\"data/\"+name+\".json\", 'r') as f:\n",
    "        param = json.load(f)\n",
    "    return df, param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing or development purposes\n",
    "df, param = stage(\"llm_rag_log_encoder\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2 - create and initialize a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "name": "mltkc_init",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initialize your model\n",
    "# available inputs: data and parameters\n",
    "# returns the model object which will be used as a reference to call fit, apply and summary subsequently\n",
    "def init(df,param):\n",
    "    model = {}   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing or development purposes\n",
    "model = init(df,param)\n",
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 3 - fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "name": "mltkc_fit",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train your model\n",
    "# returns a fit info json object and may modify the model object\n",
    "def fit(model,df,param):  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing or development purposes\n",
    "print(fit(model,df,param))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 4 - apply the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "name": "mltkc_apply",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply(model,df,param):\n",
    "    result_dict = {\"embedder_Info\": [\"No Result\"], \"vector_Store_Info\": [\"No Result\"], \"message\": [\"\"]}\n",
    "    \n",
    "    try:\n",
    "        collection_name = param['options']['params']['collection_name'].strip('\\\"')\n",
    "    except:\n",
    "        data = None\n",
    "        result_dict[\"message\"].append(\"Please specify a collection_name parameter for the vectorDB collection.\")\n",
    "        return pd.DataFrame(data=result_dict)\n",
    "\n",
    "    try:\n",
    "        vec_service = param['options']['params']['vectordb_service'].strip('\\\"')\n",
    "        print(f\"Using {vec_service} vector database service\")\n",
    "    except:\n",
    "        vec_service = \"milvus\"\n",
    "        print(\"Using default Milvus vector database service\")\n",
    "    \n",
    "    try:\n",
    "        service = param['options']['params']['embedder_service'].strip('\\\"')\n",
    "        print(f\"Using {service} embedding service\")\n",
    "    except:\n",
    "        service = \"huggingface\"\n",
    "        print(\"Using default Huggingface embedding service\")\n",
    "        \n",
    "    try:\n",
    "        use_local= int(param['options']['params']['use_local'])\n",
    "    except:\n",
    "        use_local=0\n",
    "\n",
    "    try:\n",
    "        label_field_name=param['options']['params']['label_field_name']\n",
    "    except:\n",
    "        data = None\n",
    "        result_dict[\"message\"] = [\"Failed to preprocess data. Please specify a label_field_name parameter for the field to encode.\"]\n",
    "        return pd.DataFrame(data=result_dict)\n",
    "\n",
    "    try:\n",
    "        embedder_dimension = int(param['options']['params']['embedder_dimension'])\n",
    "    except:\n",
    "        embedder_dimension = None\n",
    "        print(\"embedder_dimension not specified.\")\n",
    "    \n",
    "    try:\n",
    "        embedder_name = param['options']['params']['embedder_name'].strip('\\\"')\n",
    "    except:\n",
    "        embedder_name = None\n",
    "        print(\"embedder_name not specified.\")\n",
    "\n",
    "    try:\n",
    "        use_local = int(param['options']['params']['use_local'])\n",
    "    except:\n",
    "        use_local = 0\n",
    "        print(\"Not using local model.\")\n",
    "\n",
    "    try:\n",
    "        embedder, output_dims, m = create_embedding_model(service=service, model=embedder_name, use_local=use_local)\n",
    "\n",
    "        if embedder is not None:\n",
    "            result_dict[\"embedder_Info\"] = [m]\n",
    "        else:\n",
    "            message = f\"ERROR in embedding model loading: {m}. \"\n",
    "            result_dict[\"message\"] = [m]\n",
    "            return pd.DataFrame(data=result_dict)\n",
    "        if output_dims:\n",
    "            embedder_dimension = output_dims       \n",
    "    except Exception as e:\n",
    "        m = f\"Failed to initiate embedding model. ERROR: {e}\"\n",
    "        result_dict[\"message\"] = [m]\n",
    "        return pd.DataFrame(data=result_dict)\n",
    "\n",
    "    try:\n",
    "        df=df.copy()\n",
    "        text_df = df[label_field_name].astype(str).tolist()\n",
    "        meta_df = df.drop(label_field_name, axis=1).astype(str)\n",
    "\n",
    "        if meta_df.empty:\n",
    "            documents = [Document(text=text) for text in text_df]            \n",
    "        else:\n",
    "            meta_records = meta_df.to_dict('records')\n",
    "            meta_fields = meta_df.columns.tolist()\n",
    "            documents = [Document(text=text, metadata=meta, excluded_embed_metadata_keys=meta_fields, excluded_llm_metadata_keys=meta_fields) for text, meta in zip(text_df, meta_records)]\n",
    "\n",
    "        doc_count = len(documents)\n",
    "    except KeyError as e:\n",
    "        data = None\n",
    "        result_dict[\"message\"] = f\"Failed at data preprocessing. Could not find label_field_name {label_field_name} in data. ERROR:{e}\"\n",
    "        return pd.DataFrame(data=result_dict)\n",
    "    except Exception as e:\n",
    "        data = None\n",
    "        result_dict[\"message\"] = f\"Failed at data preprocessing. ERROR:{e}\"\n",
    "        return pd.DataFrame(data=result_dict)\n",
    "\n",
    "    if (documents is None) or (embedder is None):\n",
    "        result_dict[\"message\"] = f\"Failed to load input data or embedding model. Input data:{documents}, Embedding model:{embedder}\"\n",
    "        return pd.DataFrame(data=result_dict)\n",
    "        \n",
    "    try:\n",
    "        Settings.llm = None\n",
    "        Settings.embed_model = embedder\n",
    "        # similarity_metric set to default value: IP (inner-product)\n",
    "        vector_store, v_m = create_vector_db(service=vec_service, collection_name=collection_name, dim=embedder_dimension)\n",
    "        if vector_store is None:\n",
    "            result_dict[\"message\"] = f\"Failed at creating vectordb object. ERROR:{v_m}\"\n",
    "            return pd.DataFrame(data=result_dict)\n",
    "        storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "        VectorStoreIndex.from_documents(\n",
    "            documents, storage_context=storage_context\n",
    "        )\n",
    "\n",
    "        result_dict[\"message\"] = \"Success\"\n",
    "        result_dict[\"embedder_Info\"] = [m]\n",
    "        result_dict[\"vector_Store_Info\"] = [str(vector_store)]\n",
    "\n",
    "    except Exception as e:\n",
    "        result_dict[\"message\"] = f\"Failed at vectorization. ERROR:{e}\"\n",
    "        return pd.DataFrame(data=result_dict)\n",
    "    \n",
    "    return pd.DataFrame(data=result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# THIS CELL IS NOT EXPORTED - free notebook cell for testing or development purposes\n",
    "print(apply(model,df,param))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 5 - save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "name": "mltkc_save",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save model to name in expected convention \"<algo_name>_<model_name>\"\n",
    "def save(model,name):\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 6 - load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "name": "mltkc_load",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load model from name in expected convention \"<algo_name>_<model_name>\"\n",
    "def load(name):\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 7 - provide a summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "deletable": false,
    "name": "mltkc_summary"
   },
   "outputs": [],
   "source": [
    "# return a model summary\n",
    "def summary(model=None):\n",
    "    returns = {\"version\": {\"numpy\": np.__version__, \"pandas\": pd.__version__} }\n",
    "    return returns\n",
    "\n",
    "def compute(model,df,param):\n",
    "    result_dict = {\"embedder_Info\": [\"No Result\"], \"vector_Store_Info\": [\"No Result\"], \"message\": [\"\"]}\n",
    "    \n",
    "    try:\n",
    "        collection_name = param['options']['params']['collection_name'].strip('\\\"')\n",
    "    except:\n",
    "        data = None\n",
    "        result_dict[\"message\"].append(\"Please specify a collection_name parameter for the vectorDB collection.\")\n",
    "        return pd.DataFrame(data=result_dict)\n",
    "\n",
    "    try:\n",
    "        vec_service = param['options']['params']['vectordb_service'].strip('\\\"')\n",
    "        print(f\"Using {vec_service} vector database service\")\n",
    "    except:\n",
    "        vec_service = \"milvus\"\n",
    "        print(\"Using default Milvus vector database service\")\n",
    "    \n",
    "    try:\n",
    "        service = param['options']['params']['embedder_service'].strip('\\\"')\n",
    "        print(f\"Using {service} embedding service\")\n",
    "    except:\n",
    "        service = \"huggingface\"\n",
    "        print(\"Using default Huggingface embedding service\")\n",
    "        \n",
    "    try:\n",
    "        use_local= int(param['options']['params']['use_local'])\n",
    "    except:\n",
    "        use_local=0\n",
    "\n",
    "    try:\n",
    "        label_field_name=param['options']['params']['label_field_name']\n",
    "    except:\n",
    "        data = None\n",
    "        result_dict[\"message\"] = [\"Failed to preprocess data. Please specify a label_field_name parameter for the field to encode.\"]\n",
    "        return pd.DataFrame(data=result_dict)\n",
    "\n",
    "    try:\n",
    "        embedder_dimension = int(param['options']['params']['embedder_dimension'])\n",
    "    except:\n",
    "        embedder_dimension = None\n",
    "        print(\"embedder_dimension not specified.\")\n",
    "    \n",
    "    try:\n",
    "        embedder_name = param['options']['params']['embedder_name'].strip('\\\"')\n",
    "    except:\n",
    "        embedder_name = None\n",
    "        print(\"embedder_name not specified.\")\n",
    "\n",
    "    try:\n",
    "        use_local = int(param['options']['params']['use_local'])\n",
    "    except:\n",
    "        use_local = 0\n",
    "        print(\"Not using local model.\")\n",
    "\n",
    "    try:\n",
    "        embedder, output_dims, m = create_embedding_model(service=service, model=embedder_name, use_local=use_local)\n",
    "\n",
    "        if embedder is not None:\n",
    "            result_dict[\"embedder_Info\"] = [m]\n",
    "        else:\n",
    "            message = f\"ERROR in embedding model loading: {m}. \"\n",
    "            result_dict[\"message\"] = [m]\n",
    "            return pd.DataFrame(data=result_dict)\n",
    "        if output_dims:\n",
    "            embedder_dimension = output_dims       \n",
    "    except Exception as e:\n",
    "        m = f\"Failed to initiate embedding model. ERROR: {e}\"\n",
    "        result_dict[\"message\"] = [m]\n",
    "        return pd.DataFrame(data=result_dict)\n",
    "\n",
    "    try:\n",
    "        df=df.copy()\n",
    "        text_df = df[label_field_name].astype(str).tolist()\n",
    "        meta_df = df.drop(label_field_name, axis=1).astype(str)\n",
    "\n",
    "        if meta_df.empty:\n",
    "            documents = [Document(text=text) for text in text_df]            \n",
    "        else:\n",
    "            meta_records = meta_df.to_dict('records')\n",
    "            meta_fields = meta_df.columns.tolist()\n",
    "            documents = [Document(text=text, metadata=meta, excluded_embed_metadata_keys=meta_fields, excluded_llm_metadata_keys=meta_fields) for text, meta in zip(text_df, meta_records)]\n",
    "\n",
    "        doc_count = len(documents)\n",
    "    except KeyError as e:\n",
    "        data = None\n",
    "        result_dict[\"message\"] = f\"Failed at data preprocessing. Could not find label_field_name {label_field_name} in data. ERROR:{e}\"\n",
    "        return pd.DataFrame(data=result_dict)\n",
    "    except Exception as e:\n",
    "        data = None\n",
    "        result_dict[\"message\"] = f\"Failed at data preprocessing. ERROR:{e}\"\n",
    "        return pd.DataFrame(data=result_dict)\n",
    "\n",
    "    if (documents is None) or (embedder is None):\n",
    "        result_dict[\"message\"] = f\"Failed to load input data or embedding model. Input data:{documents}, Embedding model:{embedder}\"\n",
    "        return pd.DataFrame(data=result_dict)\n",
    "        \n",
    "    try:\n",
    "        Settings.llm = None\n",
    "        Settings.embed_model = embedder\n",
    "        # similarity_metric set to default value: IP (inner-product)\n",
    "        vector_store, v_m = create_vector_db(service=vec_service, collection_name=collection_name, dim=embedder_dimension)\n",
    "        if vector_store is None:\n",
    "            result_dict[\"message\"] = f\"Failed at creating vectordb object. ERROR:{v_m}\"\n",
    "            return pd.DataFrame(data=result_dict)\n",
    "        storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "        VectorStoreIndex.from_documents(\n",
    "            documents, storage_context=storage_context\n",
    "        )\n",
    "\n",
    "        result_dict[\"message\"] = \"Success\"\n",
    "        result_dict[\"embedder_Info\"] = [m]\n",
    "        result_dict[\"vector_Store_Info\"] = [str(vector_store)]\n",
    "\n",
    "    except Exception as e:\n",
    "        result_dict[\"message\"] = f\"Failed at vectorization. ERROR:{e}\"\n",
    "        return pd.DataFrame(data=result_dict)\n",
    "    \n",
    "    return pd.DataFrame(data=result_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After implementing your fit, apply, save and load you can train your model:<br>\n",
    "| makeresults count=10<br>\n",
    "| streamstats c as i<br>\n",
    "| eval s = i%3<br>\n",
    "| eval feature_{s}=0<br>\n",
    "| foreach feature_* [eval &lt;&lt;FIELD&gt;&gt;=random()/pow(2,31)]<br>\n",
    "| fit MLTKContainer algo=barebone s from feature_* into app:barebone_model<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or apply your model:<br>\n",
    "| makeresults count=10<br>\n",
    "| streamstats c as i<br>\n",
    "| eval s = i%3<br>\n",
    "| eval feature_{s}=0<br>\n",
    "| foreach feature_* [eval &lt;&lt;FIELD&gt;&gt;=random()/pow(2,31)]<br>\n",
    "| apply barebone_model as the_meaning_of_life"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send data back to Splunk HEC\n",
    "When you configured the Splunk HEC Settings in the DSDL app you can easily send back data to an index with [Splunk's HTTP Event Collector (HEC)](https://docs.splunk.com/Documentation/Splunk/latest/Data/UsetheHTTPEventCollector). Read more about data formats and options in the [documentation](https://docs.splunk.com/Documentation/Splunk/latest/Data/FormateventsforHTTPEventCollector#Event_metadata).\n",
    "\n",
    "### Use cases\n",
    "- you want to offload longer running, possibly distributed computations that need to deliver results asynchroneously back into Splunk. \n",
    "- you might not want to present results back into the search pipeline after your `| fit` or `| apply` command. \n",
    "- you can easily utilize this approach for any logging purposes or other profiling tasks in your ML code so you can actively monitor and analyze your processes.\n",
    "\n",
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsdlsupport import SplunkHEC as SplunkHEC\n",
    "hec = SplunkHEC.SplunkHEC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example to send 10 hello world events\n",
    "response = hec.send_hello_world(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEC endpoint http://host.docker.internal:8088/services/collector/event \n",
      "returned with status code 200 \n",
      "and response message: {\"text\":\"Success\",\"code\":0}\n"
     ]
    }
   ],
   "source": [
    "print(\"HEC endpoint %s \\nreturned with status code %s \\nand response message: %s\" % (response.url, response.status_code, response.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example to send a JSON object, e.g. to log some data\n",
    "from datetime import datetime\n",
    "response = hec.send({'event': {'message': 'operation done', 'log_level': 'INFO' }, 'time': datetime.now().timestamp()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEC endpoint http://host.docker.internal:8088/services/collector/event \n",
      "returned with status code 200 \n",
      "and response message: {\"text\":\"Success\",\"code\":0}\n"
     ]
    }
   ],
   "source": [
    "print(\"HEC endpoint %s \\nreturned with status code %s \\nand response message: %s\" % (response.url, response.status_code, response.text))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Stages\n",
    "All subsequent cells are not tagged and can be used for further freeform code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
